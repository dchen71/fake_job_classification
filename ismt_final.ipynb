{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ismt_final",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96efd6d697fa462683b465d4baafa0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15478d69707b47188aaeedf99eb01e6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c79ef4ce742a4bc39721ee9d87b22704",
              "IPY_MODEL_e04ace75e8424c68ad82881741a5c965"
            ]
          }
        },
        "15478d69707b47188aaeedf99eb01e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c79ef4ce742a4bc39721ee9d87b22704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60e1bd8d48704d52af9d3bf27a4d12d6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e7d0bffcaff49ad88b9e6bdf72e1435"
          }
        },
        "e04ace75e8424c68ad82881741a5c965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76281635a37340079e55a0a06c6fc226",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 572kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a09af7fe13104c3fa49a37636924e576"
          }
        },
        "60e1bd8d48704d52af9d3bf27a4d12d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e7d0bffcaff49ad88b9e6bdf72e1435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76281635a37340079e55a0a06c6fc226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a09af7fe13104c3fa49a37636924e576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fda4e1e41d454782ae5ca53825ec75e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0794745c81e465b9b87928f8f1ed7e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eae08f53bdf14d94b5b04f7362016288",
              "IPY_MODEL_4b4554f11ceb43479e2468ab7c598834"
            ]
          }
        },
        "d0794745c81e465b9b87928f8f1ed7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eae08f53bdf14d94b5b04f7362016288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4b8aa0bd1a940fa98a688437fb36d0a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eb385ab3c1e46739a1d44a67a745141"
          }
        },
        "4b4554f11ceb43479e2468ab7c598834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd5597199cc2495bacf4530e5a19a3ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:07&lt;00:00, 60.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c00bd2c5e9e4a85ac7910e2429a1033"
          }
        },
        "c4b8aa0bd1a940fa98a688437fb36d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eb385ab3c1e46739a1d44a67a745141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd5597199cc2495bacf4530e5a19a3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c00bd2c5e9e4a85ac7910e2429a1033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e064e540c93a4858a9a2e9d975c78bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93007d59281347328af70470390ded96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05b8d35af91743c68f7849af688b4761",
              "IPY_MODEL_af69f727978748f9a7d9efe68e6d18b6"
            ]
          }
        },
        "93007d59281347328af70470390ded96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05b8d35af91743c68f7849af688b4761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0988c258f8424db89e883c37bafe744d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7ddcb1ff71744189bf419ca86443e46"
          }
        },
        "af69f727978748f9a7d9efe68e6d18b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5fc392ea13934784b1437a7940782c54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 63.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc4295a8730c462689c26b3e7662e7f9"
          }
        },
        "0988c258f8424db89e883c37bafe744d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7ddcb1ff71744189bf419ca86443e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fc392ea13934784b1437a7940782c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc4295a8730c462689c26b3e7662e7f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a49513f321f41c498f5f2ac3eca176d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_abb39cd87778403e8f6fe91ca54037dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e32f717b8365411498ef74d3497fcf5a",
              "IPY_MODEL_3c487732e6154a9a8831adf53013c78d"
            ]
          }
        },
        "abb39cd87778403e8f6fe91ca54037dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e32f717b8365411498ef74d3497fcf5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_128bc49526414eebb2a9963d66ab64b4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a5022fd7499436b9c6e73d9d4e34cc1"
          }
        },
        "3c487732e6154a9a8831adf53013c78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00f3c37fdaeb46e9857a7d59af9f98a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 2.81kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edbf1ffd821c437085972744febd5da9"
          }
        },
        "128bc49526414eebb2a9963d66ab64b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a5022fd7499436b9c6e73d9d4e34cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00f3c37fdaeb46e9857a7d59af9f98a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edbf1ffd821c437085972744febd5da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60185ddc58a249f7ab0590e71dd72c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a5fac0dba1b4ca284adbc24124658de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6f351d143824e5a8080756a076b5465",
              "IPY_MODEL_61c7097777cc4b8f9e8041d1ca002b39"
            ]
          }
        },
        "9a5fac0dba1b4ca284adbc24124658de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6f351d143824e5a8080756a076b5465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60001b655cec4216bc6399baa5155412",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2646f07ada04488b01ad483bb63e7cf"
          }
        },
        "61c7097777cc4b8f9e8041d1ca002b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03717900d6354acf97a6b0b75fdaa19b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:29&lt;00:00, 9.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7a41db7ab5f440bbaad6aa74c4458cc"
          }
        },
        "60001b655cec4216bc6399baa5155412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2646f07ada04488b01ad483bb63e7cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03717900d6354acf97a6b0b75fdaa19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7a41db7ab5f440bbaad6aa74c4458cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaf28d4bd47b4ecca532bea8d1f8135c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8a4e744346d494ba4579b605a20f9a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1ce8a105eb94397b8a4f1e5a10baeb0",
              "IPY_MODEL_ea40f1ded2d34726a9a3eb799c11b6cd"
            ]
          }
        },
        "d8a4e744346d494ba4579b605a20f9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1ce8a105eb94397b8a4f1e5a10baeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fcb2d2af01dc49768b1086767c551f49",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c21a86432d34c919a25cf3521396260"
          }
        },
        "ea40f1ded2d34726a9a3eb799c11b6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a23df5efa314a71937b99f4c62b1c4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 3.86kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5d9bea3beb845b3be717e827414b54a"
          }
        },
        "fcb2d2af01dc49768b1086767c551f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c21a86432d34c919a25cf3521396260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a23df5efa314a71937b99f4c62b1c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5d9bea3beb845b3be717e827414b54a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e55a819618d4d83b7652e7147db995e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4da1e463bed44960a98410ff7d4eecc6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea3fd52677374fcc9eeaf972c56b419f",
              "IPY_MODEL_4781e45dfe9240acb5c5ceacdc1ddbfd"
            ]
          }
        },
        "4da1e463bed44960a98410ff7d4eecc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea3fd52677374fcc9eeaf972c56b419f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a12506c486b1412bae0feca9882756f1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eea29323922e4d65be5473671f05ea4f"
          }
        },
        "4781e45dfe9240acb5c5ceacdc1ddbfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_853252f5aa1e4bc0bc3e847902286cfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:07&lt;00:00, 68.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8456f8b640a948cca54010ef0d4872e5"
          }
        },
        "a12506c486b1412bae0feca9882756f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eea29323922e4d65be5473671f05ea4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "853252f5aa1e4bc0bc3e847902286cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8456f8b640a948cca54010ef0d4872e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e7172a7ef404c858876062ca473c959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f1a850fe7534d409961b6db520d86f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_227f10ba6ac44744b8fc95508e0760dc",
              "IPY_MODEL_6859565133934e9599e4f5b7c15aa667"
            ]
          }
        },
        "0f1a850fe7534d409961b6db520d86f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "227f10ba6ac44744b8fc95508e0760dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_959b89ad45714449b733c143d00c191a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28f17d77cacc415891d9679875efadb3"
          }
        },
        "6859565133934e9599e4f5b7c15aa667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ea51c2a5ea74b7fbc98d6c970497dd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 480kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bf6b0b3371c4a029bb4e8d62cd35553"
          }
        },
        "959b89ad45714449b733c143d00c191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28f17d77cacc415891d9679875efadb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ea51c2a5ea74b7fbc98d6c970497dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bf6b0b3371c4a029bb4e8d62cd35553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2063fcb80d1740c682a1edc437d7574c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a17841d1d94e4bc9805000f4e5fbaa97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20d57dbcfe504bbdb786120bc225aea7",
              "IPY_MODEL_758f1e4e2ab14130b311ba073636bbe3"
            ]
          }
        },
        "a17841d1d94e4bc9805000f4e5fbaa97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20d57dbcfe504bbdb786120bc225aea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d5bc65a9fc65423283300b365eec689b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a79efa61a3f74fd2862009e30d171188"
          }
        },
        "758f1e4e2ab14130b311ba073636bbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b905ab4f5c65438fbbe215438b3d108b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 841kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92b5d57d720b419586ee895a6f42115b"
          }
        },
        "d5bc65a9fc65423283300b365eec689b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a79efa61a3f74fd2862009e30d171188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b905ab4f5c65438fbbe215438b3d108b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92b5d57d720b419586ee895a6f42115b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6e591904d7e47a7ab585215c92dc00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d15f18a3f9414930922798e455e73854",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b1a0ef0993a409d9ef6de85a3eb0ced",
              "IPY_MODEL_4d3b880875764ac1bd1bfaea75379723"
            ]
          }
        },
        "d15f18a3f9414930922798e455e73854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b1a0ef0993a409d9ef6de85a3eb0ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc431254d84940fe8ca81479048e4562",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11371,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11371,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87d38a7472674b9f9d5b588194465e60"
          }
        },
        "4d3b880875764ac1bd1bfaea75379723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3bc18c266b224b798156f298b778bcb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11371/11371 [01:26&lt;00:00, 131.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83e5bb9e8ad945bf9544b256fdd20fc3"
          }
        },
        "cc431254d84940fe8ca81479048e4562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87d38a7472674b9f9d5b588194465e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bc18c266b224b798156f298b778bcb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83e5bb9e8ad945bf9544b256fdd20fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02b38f1ef06a4c619ef50c2401c82cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6f9195443af48a98a0f2360d47a5810",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1ba1b1386494ebc8fceeb2cf44bc2b8",
              "IPY_MODEL_d3c33c4039c543d0afaaff52a35a664e"
            ]
          }
        },
        "e6f9195443af48a98a0f2360d47a5810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1ba1b1386494ebc8fceeb2cf44bc2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8547862659fb4579aec7b9f960dd3069",
            "_dom_classes": [],
            "description": "Epoch 3 of 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24395d6a83534c858763dbf0e1c8369f"
          }
        },
        "d3c33c4039c543d0afaaff52a35a664e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e9f3a2fb2dd49e8b801653f5f451d29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [09:56&lt;00:00, 198.95s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4913a791591f4101a7a27c532d56dcd7"
          }
        },
        "8547862659fb4579aec7b9f960dd3069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24395d6a83534c858763dbf0e1c8369f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e9f3a2fb2dd49e8b801653f5f451d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4913a791591f4101a7a27c532d56dcd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a16ce5b12e649c1b3349d0dbd57d0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_492612668ef34ee592619f49a8f7167a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a3279f5f73cb42698c86f6b13d42cc1a",
              "IPY_MODEL_b583bdd7312c4d7695a2ea5c344b4204"
            ]
          }
        },
        "492612668ef34ee592619f49a8f7167a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3279f5f73cb42698c86f6b13d42cc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95babaf4a6d54b888031035e572053a6",
            "_dom_classes": [],
            "description": "Epochs 0/3. Running Loss:    0.0004: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96ff97755505486c9f382c03e78c4a3e"
          }
        },
        "b583bdd7312c4d7695a2ea5c344b4204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41f21ffccda540988f2703a0889f5fe7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [06:01&lt;00:00,  3.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89523cef250c453190828fe4c0aeca89"
          }
        },
        "95babaf4a6d54b888031035e572053a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96ff97755505486c9f382c03e78c4a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41f21ffccda540988f2703a0889f5fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89523cef250c453190828fe4c0aeca89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06a0778e71d34e4095e77e6f8b9039c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6db060188fbf4a5fa906cb080ef8601a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4232dccd243e4eb9898626b58e5254f6",
              "IPY_MODEL_82a7a6089f4447d59d357ba359702ec9"
            ]
          }
        },
        "6db060188fbf4a5fa906cb080ef8601a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4232dccd243e4eb9898626b58e5254f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aceeb7e180514eeabf19d0cb8482b545",
            "_dom_classes": [],
            "description": "Epochs 1/3. Running Loss:    0.0001: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0683ab514cff4754b5b7f62ddc7b511b"
          }
        },
        "82a7a6089f4447d59d357ba359702ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a5eb95877154cd4b1dc52c5d3c93dae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [06:53&lt;00:00,  3.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f86fca4b5adf4156b5e7a3f51bb86eef"
          }
        },
        "aceeb7e180514eeabf19d0cb8482b545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0683ab514cff4754b5b7f62ddc7b511b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a5eb95877154cd4b1dc52c5d3c93dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f86fca4b5adf4156b5e7a3f51bb86eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3e4c2eeb180407ea2505baa67ba8aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1aa58436b3e9401499d5ac5784e26af1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9daf0c2278e476db86939b2bf653f03",
              "IPY_MODEL_5ab75e0c53b942a6b8cbd833df1d985e"
            ]
          }
        },
        "1aa58436b3e9401499d5ac5784e26af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9daf0c2278e476db86939b2bf653f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03385e2f667249cf961a903fe469b48d",
            "_dom_classes": [],
            "description": "Epochs 2/3. Running Loss:    0.0001: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da0b69689980431f82bac4d29cde73c1"
          }
        },
        "5ab75e0c53b942a6b8cbd833df1d985e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_951e19c808224781ac93dbe520307d8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [03:51&lt;00:00,  6.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a02db8cfebb440587e6305cc9b26796"
          }
        },
        "03385e2f667249cf961a903fe469b48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da0b69689980431f82bac4d29cde73c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "951e19c808224781ac93dbe520307d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a02db8cfebb440587e6305cc9b26796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8819480b58b472a8e5bcb99c46574bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e27248153cb140a2a92ae86d40c4a1b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3b603ffde234ee092577a5a76993319",
              "IPY_MODEL_7f5ad022118c490886313c08120faea6"
            ]
          }
        },
        "e27248153cb140a2a92ae86d40c4a1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3b603ffde234ee092577a5a76993319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a9d05b1f9cb43a79bb9cb18b8532c93",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3245,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3245,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87401e6387cd4bf39185953e54e7fde5"
          }
        },
        "7f5ad022118c490886313c08120faea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84fd97c13b3649d483d8b5e7a21e1c85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3245/3245 [00:33&lt;00:00, 96.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6d8cf7c53a94f04a649ebf2b6bdbd6a"
          }
        },
        "cab3d997471f43178a13d528133221bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d1c533db2ad453f8428ea7d1d63e03c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_38fd870d97ad4d0b98589c585f760946",
              "IPY_MODEL_065f0e59380e4b888bda393d784ad731"
            ]
          }
        },
        "419ddca79bf744c79006a394e2aa6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84bd245c28bb4b618646174aaa16a7b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05489e4efd5d4a048119fa5014ca3e05",
              "IPY_MODEL_efc11471d33e43d9ba4db037935e0957"
            ]
          }
        },
        "84bd245c28bb4b618646174aaa16a7b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05489e4efd5d4a048119fa5014ca3e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6af6d04d7f0a4cd2b0842f05892a2c27",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11371,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11371,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_474f0ac3394d40bdbe2d6b474fb42e62"
          }
        },
        "efc11471d33e43d9ba4db037935e0957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7e77a8615ae478ebfb080d23abd55ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11371/11371 [05:03&lt;00:00, 37.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8e8bd418d2644e68c5ce64aac2decc8"
          }
        },
        "6af6d04d7f0a4cd2b0842f05892a2c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "474f0ac3394d40bdbe2d6b474fb42e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7e77a8615ae478ebfb080d23abd55ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8e8bd418d2644e68c5ce64aac2decc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "476bc01abd6d4b6e8fd42e8e033393cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c319fce527a04c18b28e0a5299b87c2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2140390f82b940ed984a86d42da60ab6",
              "IPY_MODEL_b9b11141a3cb4108b3b6f702727b6073"
            ]
          }
        },
        "c319fce527a04c18b28e0a5299b87c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2140390f82b940ed984a86d42da60ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67f78432c9d047299f6fca2961ce4c12",
            "_dom_classes": [],
            "description": "Epoch 3 of 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a38e94159c354f1a8b08a72ec787ffb2"
          }
        },
        "b9b11141a3cb4108b3b6f702727b6073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08ba6618fbe94c3195e3777c46fb5b64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [13:54&lt;00:00, 278.29s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55c64ec5f4674b728d3b9362cd54cee9"
          }
        },
        "67f78432c9d047299f6fca2961ce4c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a38e94159c354f1a8b08a72ec787ffb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08ba6618fbe94c3195e3777c46fb5b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55c64ec5f4674b728d3b9362cd54cee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ba69ca221fa4be7ad9b934f095b018f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47e2451a184d4e5d8a0fa8c88f547056",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de455c66161b4915b42f6bae5f1f1bd2",
              "IPY_MODEL_6285542ac45b40d785a10959a2da89c5"
            ]
          }
        },
        "47e2451a184d4e5d8a0fa8c88f547056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de455c66161b4915b42f6bae5f1f1bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53405648006541788b4b64179f74e280",
            "_dom_classes": [],
            "description": "Epochs 0/3. Running Loss:    0.0131: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0b4b5b0872a471b9e605d5357245b06"
          }
        },
        "6285542ac45b40d785a10959a2da89c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c9737aa17ab944b7afb3225dac806373",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [04:46&lt;00:00,  4.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fcc9a9774904b4ea2adad78603df103"
          }
        },
        "53405648006541788b4b64179f74e280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0b4b5b0872a471b9e605d5357245b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9737aa17ab944b7afb3225dac806373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fcc9a9774904b4ea2adad78603df103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62e723fd0d2d43d9a831204b644f1936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3aca46efb7084f208ca781fdfb5865f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_159e18b6e493454d92880b2f284f2ca0",
              "IPY_MODEL_3ba0cfb77ed540f08e08831ed6e4ae59"
            ]
          }
        },
        "3aca46efb7084f208ca781fdfb5865f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "159e18b6e493454d92880b2f284f2ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb21e36635c54e5b90e230da44ecbf39",
            "_dom_classes": [],
            "description": "Epochs 1/3. Running Loss:    0.0040: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48c88869a5e4451fb8e26a22cc9594f7"
          }
        },
        "3ba0cfb77ed540f08e08831ed6e4ae59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0405444d985b4d1c80f03eb757958355",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [06:50&lt;00:00,  3.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_893cf12b9f3848a480b30026ec7dfd7a"
          }
        },
        "cb21e36635c54e5b90e230da44ecbf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48c88869a5e4451fb8e26a22cc9594f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0405444d985b4d1c80f03eb757958355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "893cf12b9f3848a480b30026ec7dfd7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6e5926d753f44fa8f0734e233851d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a4244170011e4e889e5f0a9c9748ac3d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_823e0d511a0149888a97ab431d85bc6a",
              "IPY_MODEL_f4c67b3312be48b98f3fe8fa0cd86703"
            ]
          }
        },
        "a4244170011e4e889e5f0a9c9748ac3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "823e0d511a0149888a97ab431d85bc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_689191f7088e4bad95bc433575f49ef1",
            "_dom_classes": [],
            "description": "Epochs 2/3. Running Loss:    0.0004: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3db057fec0be44f39041726c4ea731ba"
          }
        },
        "f4c67b3312be48b98f3fe8fa0cd86703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0eedd2cbe42444efbdaaa65059310891",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [07:00&lt;00:00,  3.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ec4261bdc8f4088bc812408449d43fa"
          }
        },
        "689191f7088e4bad95bc433575f49ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3db057fec0be44f39041726c4ea731ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0eedd2cbe42444efbdaaa65059310891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ec4261bdc8f4088bc812408449d43fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11d6e9aa03db4748836608f1adbe04c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_19d0dab2aa304d6fa8adf5b0724c315b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7775b49d68354935af18679123ffc30e",
              "IPY_MODEL_a5a54469f2224b7481307b39ac8da6df"
            ]
          }
        },
        "19d0dab2aa304d6fa8adf5b0724c315b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7775b49d68354935af18679123ffc30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_047b7ab9b6444d58a49890018d4c0cef",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11371,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11371,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a63d22912f44dc9a302a57b1e726c7d"
          }
        },
        "a5a54469f2224b7481307b39ac8da6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d76c0308ab1e44a28cd0b4319bdfc522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11371/11371 [02:44&lt;00:00, 69.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_784b7a19e5d34b008cbaa5f8ee2451d3"
          }
        },
        "047b7ab9b6444d58a49890018d4c0cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a63d22912f44dc9a302a57b1e726c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d76c0308ab1e44a28cd0b4319bdfc522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "784b7a19e5d34b008cbaa5f8ee2451d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60da1bed6d0b480684b8a9e5088bca24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c4d6e34835746d5a1ba7507e06ef39a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a416e19247a4048b34ea9c01ab14d56",
              "IPY_MODEL_4de1adfa48994e9a8710280f0a68e4c1"
            ]
          }
        },
        "8c4d6e34835746d5a1ba7507e06ef39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a416e19247a4048b34ea9c01ab14d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f84f218c4f84fcba4885597a02e4c2d",
            "_dom_classes": [],
            "description": "Epoch 3 of 3: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebe6a8f2eca6483cbf50463a91bdbea5"
          }
        },
        "4de1adfa48994e9a8710280f0a68e4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56da9191c8334023851101439faf4592",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [11:36&lt;00:00, 232.25s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b05e34cb63842998b38c85521865f29"
          }
        },
        "6f84f218c4f84fcba4885597a02e4c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebe6a8f2eca6483cbf50463a91bdbea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56da9191c8334023851101439faf4592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b05e34cb63842998b38c85521865f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3983cf578f984b16b9f63bfaf0376b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48cbc52d5da54e5a9a30ac8929c43fe7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b9d50f9dd654a068993feebdc834aa5",
              "IPY_MODEL_602d3ba1d2964da4980cc85bf1c63d87"
            ]
          }
        },
        "48cbc52d5da54e5a9a30ac8929c43fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b9d50f9dd654a068993feebdc834aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_585b7e77f0a648b8b5d24ee6f8d3916a",
            "_dom_classes": [],
            "description": "Epochs 0/3. Running Loss:    0.0065: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fa915d03ca54579bf567be29b417c3c"
          }
        },
        "602d3ba1d2964da4980cc85bf1c63d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_217ca733bc014e52910f1c5a1f9c8751",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [07:02&lt;00:00,  3.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42219849e6d24405881856e8497c47a7"
          }
        },
        "585b7e77f0a648b8b5d24ee6f8d3916a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fa915d03ca54579bf567be29b417c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "217ca733bc014e52910f1c5a1f9c8751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42219849e6d24405881856e8497c47a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2ffcb62f25f4781aceb12aff3252516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d21b3fc80fad4356af2cd2d75acb1234",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dcfc5c07c07342f7b8f8d0d3f10df0fe",
              "IPY_MODEL_1c741d0e93c14fa6acbb157b255913e3"
            ]
          }
        },
        "d21b3fc80fad4356af2cd2d75acb1234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcfc5c07c07342f7b8f8d0d3f10df0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b35844e0c364c0c928c2ad65c776d51",
            "_dom_classes": [],
            "description": "Epochs 1/3. Running Loss:    0.0065: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3c3d92709f6453cac8c10566a7804bd"
          }
        },
        "1c741d0e93c14fa6acbb157b255913e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_598493208af745be9f9d595b23111dd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [08:04&lt;00:00,  2.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40de99e4f0614d27a9d0ef668f4bd505"
          }
        },
        "4b35844e0c364c0c928c2ad65c776d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3c3d92709f6453cac8c10566a7804bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "598493208af745be9f9d595b23111dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40de99e4f0614d27a9d0ef668f4bd505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4ae925e0d9b448593952b0ac41d4757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_342aa6a9dbec4e429f44d676bbe4af96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6dab567834f047688c718cf9388f195a",
              "IPY_MODEL_f8ca2529c24e4c8ab07ea39bc8c13e32"
            ]
          }
        },
        "342aa6a9dbec4e429f44d676bbe4af96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dab567834f047688c718cf9388f195a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_54a1f558b2d64cdfa2de91d4b855add4",
            "_dom_classes": [],
            "description": "Epochs 2/3. Running Loss:    0.0088: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25e0c43b55ae466b9a9a16b525e05eca"
          }
        },
        "f8ca2529c24e4c8ab07ea39bc8c13e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f062865bf6894eb2a5399036d7190b50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1422/1422 [04:29&lt;00:00,  5.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05fadf3a2a7242c7aa748cfe27433fa1"
          }
        },
        "54a1f558b2d64cdfa2de91d4b855add4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25e0c43b55ae466b9a9a16b525e05eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f062865bf6894eb2a5399036d7190b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05fadf3a2a7242c7aa748cfe27433fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c2c372780ec40a19b392f6d1b906482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43ce1944ef004f05a72932c6a97802ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58dddad57ba34c538bb79e45a375fbe5",
              "IPY_MODEL_c0acf6753b6d49f9a73f2e61ac343239"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpYcTsBJtaz-",
        "colab_type": "text"
      },
      "source": [
        "# Fake Job Classification Detection\n",
        "### Daniel Chen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rd4Z7HewugK",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The unemployment rate in the United States acording to the US Department of Labor as of June 2020 is at 11.1%$^1$. Although there are many factors causing contributing to the current unemployment rate, many people in the US and worldwide need to look for new jobs due to job loss and other financial hardships. As all of the job postings are done online now, most companies can directly post to job boards or have job data pulled from job aggregators. However, not all job postings are true job postings as some are fradulent job postings used to harvest data or other sensitive information towards desperate job seekers$^2$. Using the advances in natural learning processing, it should be possible to build a classifier to be able to detect potential fake jobs. This is an important task as many people will be applying for jobs online due to the current unemployment situation, and minimizing victims of scams due to fradulent job postings will be important for economic recovery.\n",
        "\n",
        "Using data gathered from the University of Aegean about various job postings from many different job sites, it should be possible to build some a classifer for potential fake job postings. Job posts typically are text rich with general job descriptions and typically some additional information such as telecommuting options and employment type. With all of these features, it should be possible to build a complex model using features from the job description using NLP or even more simple features with simplier models. This project will use three models and with the most simple model being the baseline model to compare against.\n",
        "\n",
        "1. Simple model using non-NLP features such as comparing correlations of job function to fraudulent postings\n",
        "2. Intermediate model using NLP tokenization features and modeling relationship of fraudent job postings using more traditional machine learning algorithms such as logistic regression or SVMs\n",
        "3. Complex model using state of the art transformer neural network models to predict fradulent job postings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uITfRvI5xoaT",
        "colab_type": "text"
      },
      "source": [
        "## Data Description\n",
        "The dataset originally was downloaded from [kaggle](https://www.kaggle.com/shivamb/real-or-fake-fake-jobposting-prediction). The dataset hosted there is originally from the [University of Aegean](http://emscad.samos.aegean.gr/). This dataset is a publicly available dataset containing almost ~18,000 job ads with human classified fake jobs. This dataset is based on job ads published between 2012 and 2014. There are ~17000 true jobs and ~900 fake jobs in the dataset.  \n",
        "\n",
        "Basic exploratory data analysis will be done to help guide future development.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EFxYBbtImEE",
        "colab_type": "text"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIw3e4GNruVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0474cc05-d15c-4332-ea60-ad3dcdae7704"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XPSJJt6Ugm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob12Wfaf6VbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "7579fa41-438d-4b49-d4e3-47cb0512d064"
      },
      "source": [
        "fake_job_postings = pd.read_csv(\"/content/drive/My Drive/nlp_class/fake_job_postings.csv\")\n",
        "fake_job_postings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "      <th>location</th>\n",
              "      <th>department</th>\n",
              "      <th>salary_range</th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "      <th>requirements</th>\n",
              "      <th>benefits</th>\n",
              "      <th>telecommuting</th>\n",
              "      <th>has_company_logo</th>\n",
              "      <th>has_questions</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>required_experience</th>\n",
              "      <th>required_education</th>\n",
              "      <th>industry</th>\n",
              "      <th>function</th>\n",
              "      <th>fraudulent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Marketing Intern</td>\n",
              "      <td>US, NY, New York</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
              "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
              "      <td>Experience with content management systems a m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Other</td>\n",
              "      <td>Internship</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Customer Service - Cloud Video Production</td>\n",
              "      <td>NZ, , Auckland</td>\n",
              "      <td>Success</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
              "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
              "      <td>What we expect from you:Your key responsibilit...</td>\n",
              "      <td>What you will get from usThrough being part of...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing and Advertising</td>\n",
              "      <td>Customer Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
              "      <td>US, IA, Wever</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Valor Services provides Workforce Solutions th...</td>\n",
              "      <td>Our client, located in Houston, is actively se...</td>\n",
              "      <td>Implement pre-commissioning and commissioning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Account Executive - Washington DC</td>\n",
              "      <td>US, DC, Washington</td>\n",
              "      <td>Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our passion for improving quality of life thro...</td>\n",
              "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
              "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
              "      <td>Our culture is anything but corporate—we have ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Sales</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Bill Review Manager</td>\n",
              "      <td>US, FL, Fort Worth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
              "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
              "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
              "      <td>Full Benefits Offered</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Hospital &amp; Health Care</td>\n",
              "      <td>Health Care Provider</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   job_id  ... fraudulent\n",
              "0       1  ...          0\n",
              "1       2  ...          0\n",
              "2       3  ...          0\n",
              "3       4  ...          0\n",
              "4       5  ...          0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8gcYdiE6miY",
        "colab_type": "text"
      },
      "source": [
        "We can see various features including numerical one hot encoded variables and text data. The one hot encoded variables seem to be information about telecommuting, company logos, and if there are questions included in the posting. The text data include general information including job titles, locations, department, company information, job description and more. The variable we are interested in predicting is `fradulent`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpY2UUL2KEcY",
        "colab_type": "text"
      },
      "source": [
        "##### Basic Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOXVoV55KAh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a952dee-a21a-4618-f0a3-6694bc555bda"
      },
      "source": [
        "fake_job_postings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17880, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPqUqsOmKLKL",
        "colab_type": "text"
      },
      "source": [
        "There are about 18000 postings and 16 features that we can use. We also need to look at the potential missing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTHvbShZLE6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8aface9e-7203-49ae-d6de-84cc3b510d09"
      },
      "source": [
        "fake_job_postings.isnull().sum() / len(fake_job_postings) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "job_id                  0.000000\n",
              "title                   0.000000\n",
              "location                1.935123\n",
              "department             64.580537\n",
              "salary_range           83.959732\n",
              "company_profile        18.501119\n",
              "description             0.005593\n",
              "requirements           15.072707\n",
              "benefits               40.324385\n",
              "telecommuting           0.000000\n",
              "has_company_logo        0.000000\n",
              "has_questions           0.000000\n",
              "employment_type        19.412752\n",
              "required_experience    39.429530\n",
              "required_education     45.329978\n",
              "industry               27.421700\n",
              "function               36.101790\n",
              "fraudulent              0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F8o3oIWLOjU",
        "colab_type": "text"
      },
      "source": [
        "In the output above, we can see the percentage of missing data in each column in the dataset. The column with the largest amount of missing data is the salary which makes sense followed by department. With the amount of missing data, some columns not might be too useful but that also depends on the relative ratio based on fradulent job posts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC05d8JXNGTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "4ee17173-0a91-4b6e-f0fc-1f3fe769c238"
      },
      "source": [
        "fake_job_postings.groupby(\"fraudulent\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "      <th>location</th>\n",
              "      <th>department</th>\n",
              "      <th>salary_range</th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "      <th>requirements</th>\n",
              "      <th>benefits</th>\n",
              "      <th>telecommuting</th>\n",
              "      <th>has_company_logo</th>\n",
              "      <th>has_questions</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>required_experience</th>\n",
              "      <th>required_education</th>\n",
              "      <th>industry</th>\n",
              "      <th>function</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17014</td>\n",
              "      <td>17014</td>\n",
              "      <td>16687</td>\n",
              "      <td>5998</td>\n",
              "      <td>2645</td>\n",
              "      <td>14293</td>\n",
              "      <td>17014</td>\n",
              "      <td>14473</td>\n",
              "      <td>10168</td>\n",
              "      <td>17014</td>\n",
              "      <td>17014</td>\n",
              "      <td>17014</td>\n",
              "      <td>13784</td>\n",
              "      <td>10399</td>\n",
              "      <td>9360</td>\n",
              "      <td>12386</td>\n",
              "      <td>10896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>866</td>\n",
              "      <td>866</td>\n",
              "      <td>847</td>\n",
              "      <td>335</td>\n",
              "      <td>223</td>\n",
              "      <td>279</td>\n",
              "      <td>865</td>\n",
              "      <td>712</td>\n",
              "      <td>502</td>\n",
              "      <td>866</td>\n",
              "      <td>866</td>\n",
              "      <td>866</td>\n",
              "      <td>625</td>\n",
              "      <td>431</td>\n",
              "      <td>415</td>\n",
              "      <td>591</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            job_id  title  location  ...  required_education  industry  function\n",
              "fraudulent                           ...                                        \n",
              "0            17014  17014     16687  ...                9360     12386     10896\n",
              "1              866    866       847  ...                 415       591       529\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykLcTrXEO2Go",
        "colab_type": "text"
      },
      "source": [
        "In the table above, we can see the number of fraudulent job postings against all of the variables. We have 866 fraduent jobs which is very small compared to the relative amount of non fraudulent jobs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc0PCBp0O29s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "dc9f49b0-f005-491e-b208-2854221e5005"
      },
      "source": [
        "fake_job_postings.groupby(\"fraudulent\").count().iloc[1,] / fake_job_postings.groupby(\"fraudulent\").count().sum() * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "job_id                 4.843400\n",
              "title                  4.843400\n",
              "location               4.830615\n",
              "department             5.289752\n",
              "salary_range           7.775453\n",
              "company_profile        1.914631\n",
              "description            4.838078\n",
              "requirements           4.688838\n",
              "benefits               4.704780\n",
              "telecommuting          4.843400\n",
              "has_company_logo       4.843400\n",
              "has_questions          4.843400\n",
              "employment_type        4.337567\n",
              "required_experience    3.979686\n",
              "required_education     4.245524\n",
              "industry               4.554211\n",
              "function               4.630197\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26j1cofKO192",
        "colab_type": "text"
      },
      "source": [
        "Looking at it another way, most of our fradulent job postings only account for 5% of each feature so there is some data sparsity issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7IvzVZ6SDlY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e063f88-f2f2-422b-ec62-d9b0aaa51551"
      },
      "source": [
        "fake_job_postings.title.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf94R-TPkcZc",
        "colab_type": "text"
      },
      "source": [
        "There are 11231 unique job titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1kXG6bohQKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7d1728a-7bed-44aa-9f82-152bddf3d8e6"
      },
      "source": [
        "fake_job_postings.department.nunique()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hG5pk97kev0",
        "colab_type": "text"
      },
      "source": [
        "There are 1337 unique departments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCzhufnbkmsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0caf1c1a-b833-4cf7-a402-aa192538bdc1"
      },
      "source": [
        "fake_job_postings.location.nunique()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h1FmYnLkohF",
        "colab_type": "text"
      },
      "source": [
        "There are job postings for 3105 different locations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL-rnEoVwMem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0cadbded-961b-4276-967d-711b71fc14fa"
      },
      "source": [
        "fake_job_postings.employment_type.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Full-time    11620\n",
              "Contract      1524\n",
              "Part-time      797\n",
              "Temporary      241\n",
              "Other          227\n",
              "Name: employment_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucOihYx2xG_e",
        "colab_type": "text"
      },
      "source": [
        "We can see the different types of employment types in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEDIK-VMxfYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "340bd8de-9490-4f28-87eb-8b1d358ad423"
      },
      "source": [
        "fake_job_postings.telecommuting.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    17113\n",
              "1      767\n",
              "Name: telecommuting, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7e74KpbxsAc",
        "colab_type": "text"
      },
      "source": [
        "Most of the jobpostings are not telecommute friendly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfREOz-nxk4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "069a7502-bc3f-4d3b-b9c5-2aa0a11ed952"
      },
      "source": [
        "fake_job_postings.has_questions.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9088\n",
              "1    8792\n",
              "Name: has_questions, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcZWyvPaxG6H",
        "colab_type": "text"
      },
      "source": [
        "It seems like half of the job postings has additional questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6zTyK8zxs-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "af406311-da09-48fa-f23a-6d2062e72d23"
      },
      "source": [
        "fake_job_postings.has_company_logo.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    14220\n",
              "0     3660\n",
              "Name: has_company_logo, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsxfgZ0sxvG0",
        "colab_type": "text"
      },
      "source": [
        "It seems like most of the job postings has a company logo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-RhVOAKxvbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2b69821a-a904-492d-fa68-79528f25d732"
      },
      "source": [
        "fake_job_postings.required_education.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bachelor's Degree                    5145\n",
              "High School or equivalent            2080\n",
              "Unspecified                          1397\n",
              "Master's Degree                       416\n",
              "Associate Degree                      274\n",
              "Certification                         170\n",
              "Some College Coursework Completed     102\n",
              "Professional                           74\n",
              "Vocational                             49\n",
              "Some High School Coursework            27\n",
              "Doctorate                              26\n",
              "Vocational - HS Diploma                 9\n",
              "Vocational - Degree                     6\n",
              "Name: required_education, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJfBfOhOx54Z",
        "colab_type": "text"
      },
      "source": [
        "In the table above, we can see that the jobs mostly require High School education or above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOztQgI7x3s0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "473084fa-6a55-4442-dfed-4edc6ce47371"
      },
      "source": [
        "fake_job_postings.required_experience.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mid-Senior level    3809\n",
              "Entry level         2697\n",
              "Associate           2297\n",
              "Not Applicable      1116\n",
              "Director             389\n",
              "Internship           381\n",
              "Executive            141\n",
              "Name: required_experience, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYm9vJ7Ox6Va",
        "colab_type": "text"
      },
      "source": [
        "It seems like a lot of the jobs are entry level to senior level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFiC29mrx61s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e9d30aef-02d5-4d80-8d9e-a03a1bcea53e"
      },
      "source": [
        "fake_job_postings.industry.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Information Technology and Services    1734\n",
              "Computer Software                      1376\n",
              "Internet                               1062\n",
              "Marketing and Advertising               828\n",
              "Education Management                    822\n",
              "                                       ... \n",
              "Ranching                                  1\n",
              "Alternative Dispute Resolution            1\n",
              "Shipbuilding                              1\n",
              "Wine and Spirits                          1\n",
              "Museums and Institutions                  1\n",
              "Name: industry, Length: 131, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mZ_1elx-C5",
        "colab_type": "text"
      },
      "source": [
        "From this table, the top industry appears to be tech or tech related."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2TotJkgx-ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "35cfd88e-4f1b-48fc-fca9-12d246a80ebe"
      },
      "source": [
        "fake_job_postings.function.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Information Technology    1749\n",
              "Sales                     1468\n",
              "Engineering               1348\n",
              "Customer Service          1229\n",
              "Marketing                  830\n",
              "Administrative             630\n",
              "Design                     340\n",
              "Health Care Provider       338\n",
              "Other                      325\n",
              "Education                  325\n",
              "Management                 317\n",
              "Business Development       228\n",
              "Accounting/Auditing        212\n",
              "Human Resources            205\n",
              "Project Management         183\n",
              "Finance                    172\n",
              "Consulting                 144\n",
              "Art/Creative               132\n",
              "Writing/Editing            132\n",
              "Production                 116\n",
              "Product Management         114\n",
              "Quality Assurance          111\n",
              "Advertising                 90\n",
              "Business Analyst            84\n",
              "Data Analyst                82\n",
              "Public Relations            76\n",
              "Manufacturing               74\n",
              "General Business            68\n",
              "Research                    50\n",
              "Legal                       47\n",
              "Strategy/Planning           46\n",
              "Training                    38\n",
              "Supply Chain                36\n",
              "Financial Analyst           33\n",
              "Distribution                24\n",
              "Purchasing                  15\n",
              "Science                     14\n",
              "Name: function, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JSBnF6vzU2B",
        "colab_type": "text"
      },
      "source": [
        "Finally, from this we see that these jobs are mostly sales or tech related."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yti_6t-pMpQ5",
        "colab_type": "text"
      },
      "source": [
        "#### Fradulent Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw6Xj1orLDWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "608ab89b-013e-40ef-907b-4b7ce5622c4b"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','telecommuting']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fraudulent  telecommuting\n",
              "0           0                16311\n",
              "            1                  703\n",
              "1           0                  802\n",
              "            1                   64\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YNF2T7gMd1Y",
        "colab_type": "text"
      },
      "source": [
        "We can see that most of the fake jobs are not tele commute friendly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In_MLP9ILVg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "6c49fb06-e616-4e2a-a34c-928a2d7b43a5"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','function']).size().to_frame().sort_values(by=['fraudulent', 0 ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th>function</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th>Science</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Purchasing</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Distribution</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Financial Analyst</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Supply Chain</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th>Other</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sales</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Customer Service</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Engineering</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Administrative</th>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                0\n",
              "fraudulent function              \n",
              "0          Science             14\n",
              "           Purchasing          15\n",
              "           Distribution        21\n",
              "           Financial Analyst   28\n",
              "           Supply Chain        36\n",
              "...                           ...\n",
              "1          Other               32\n",
              "           Sales               41\n",
              "           Customer Service    67\n",
              "           Engineering        113\n",
              "           Administrative     119\n",
              "\n",
              "[64 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lIi9k-sSH1p",
        "colab_type": "text"
      },
      "source": [
        "Most of the fake jobs are in the administrative or engineering groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTibOexNMsd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "41c6e4d4-28bc-4ef9-ccbb-7a419c95498a"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','industry']).size().to_frame().sort_values(by=['fraudulent', 0 ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th>industry</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th>Alternative Dispute Resolution</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Military</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Museums and Institutions</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shipbuilding</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sporting Goods</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
              "      <th>Financial Services</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Marketing and Advertising</th>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hospital &amp; Health Care</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accounting</th>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oil &amp; Energy</th>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             0\n",
              "fraudulent industry                           \n",
              "0          Alternative Dispute Resolution    1\n",
              "           Military                          1\n",
              "           Museums and Institutions          1\n",
              "           Shipbuilding                      1\n",
              "           Sporting Goods                    1\n",
              "...                                        ...\n",
              "1          Financial Services               35\n",
              "           Marketing and Advertising        45\n",
              "           Hospital & Health Care           51\n",
              "           Accounting                       57\n",
              "           Oil & Energy                    109\n",
              "\n",
              "[192 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvX3BOziSA8o",
        "colab_type": "text"
      },
      "source": [
        "Most of the fradulent jobs appear to be coming from the energy sector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiAFQ1GYMzvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "9968819e-6eeb-47ed-a9a7-83f60e50b218"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','required_experience']).size().to_frame().sort_values(by=['fraudulent', 0 ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th>required_experience</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"7\" valign=\"top\">0</th>\n",
              "      <th>Executive</th>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Internship</th>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Director</th>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Not Applicable</th>\n",
              "      <td>1056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Associate</th>\n",
              "      <td>2255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Entry level</th>\n",
              "      <td>2518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mid-Senior level</th>\n",
              "      <td>3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
              "      <th>Executive</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Internship</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Director</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Associate</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Not Applicable</th>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mid-Senior level</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Entry level</th>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   0\n",
              "fraudulent required_experience      \n",
              "0          Executive             131\n",
              "           Internship            371\n",
              "           Director              372\n",
              "           Not Applicable       1056\n",
              "           Associate            2255\n",
              "           Entry level          2518\n",
              "           Mid-Senior level     3696\n",
              "1          Executive              10\n",
              "           Internship             10\n",
              "           Director               17\n",
              "           Associate              42\n",
              "           Not Applicable         60\n",
              "           Mid-Senior level      113\n",
              "           Entry level           179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GonY-fRJRJLX",
        "colab_type": "text"
      },
      "source": [
        "Most of the fradulent jobs are entry to senior level careers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i_tR0hqM2LB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "0170b384-ae7f-467b-9ece-d4913ac0740c"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','required_education']).size().to_frame().sort_values(by=['fraudulent', 0 ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fraudulent</th>\n",
              "      <th>required_education</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"13\" valign=\"top\">0</th>\n",
              "      <th>Vocational - Degree</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Some High School Coursework</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vocational - HS Diploma</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doctorate</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vocational</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Professional</th>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Some College Coursework Completed</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Certification</th>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Associate Degree</th>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Master's Degree</th>\n",
              "      <td>385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unspecified</th>\n",
              "      <td>1336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High School or equivalent</th>\n",
              "      <td>1910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bachelor's Degree</th>\n",
              "      <td>5045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
              "      <th>Doctorate</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Some College Coursework Completed</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Professional</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Associate Degree</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Certification</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Some High School Coursework</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Master's Degree</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unspecified</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bachelor's Degree</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High School or equivalent</th>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 0\n",
              "fraudulent required_education                     \n",
              "0          Vocational - Degree                   6\n",
              "           Some High School Coursework           7\n",
              "           Vocational - HS Diploma               9\n",
              "           Doctorate                            25\n",
              "           Vocational                           49\n",
              "           Professional                         70\n",
              "           Some College Coursework Completed    99\n",
              "           Certification                       151\n",
              "           Associate Degree                    268\n",
              "           Master's Degree                     385\n",
              "           Unspecified                        1336\n",
              "           High School or equivalent          1910\n",
              "           Bachelor's Degree                  5045\n",
              "1          Doctorate                             1\n",
              "           Some College Coursework Completed     3\n",
              "           Professional                          4\n",
              "           Associate Degree                      6\n",
              "           Certification                        19\n",
              "           Some High School Coursework          20\n",
              "           Master's Degree                      31\n",
              "           Unspecified                          61\n",
              "           Bachelor's Degree                   100\n",
              "           High School or equivalent           170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1j2QGA-Ni2Y",
        "colab_type": "text"
      },
      "source": [
        "The highest number of fake job postings required High School or Bachelor's degrees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIcjs-apM7dF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "24799e65-2af0-495f-d1a7-bf251498c2b5"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','has_company_logo']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fraudulent  has_company_logo\n",
              "0           0                    3077\n",
              "            1                   13937\n",
              "1           0                     583\n",
              "            1                     283\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ-Jycr9NYlM",
        "colab_type": "text"
      },
      "source": [
        "It seems like fradulent job postings have twice as many missing logos than with logos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbSG_bSjNXqO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "065e2a06-f360-4096-b6c6-cff076dce473"
      },
      "source": [
        "fake_job_postings.groupby(['fraudulent','has_questions']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fraudulent  has_questions\n",
              "0           0                8472\n",
              "            1                8542\n",
              "1           0                 616\n",
              "            1                 250\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1EsMljIN3Al",
        "colab_type": "text"
      },
      "source": [
        "Real job postings have and don't have questions at about the same ratio. These fake jobs have 3 times more missing questions than questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWFmzOyUJbYD",
        "colab_type": "text"
      },
      "source": [
        "#### Salary Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItfphNKzhTYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "15e0694e-fb21-4f81-bda0-2bcdb595489a"
      },
      "source": [
        "min_salary = [item[1].split(\"-\")[0] for item in fake_job_postings.salary_range.dropna().iteritems()]\n",
        "max_salary = [item[1].split(\"-\")[1] if len(item[1].split(\"-\")) > 1 else '0' for item in fake_job_postings.salary_range.dropna().iteritems()]\n",
        "fig=plt.figure()\n",
        "plt.scatter(min_salary, max_salary)\n",
        "plt.title('Minimum to Maximum Salary')\n",
        "plt.xlabel('Minimum Salary')\n",
        "plt.ylabel('Maximum Salary')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK1q_vi31uLO",
        "colab_type": "text"
      },
      "source": [
        "We can see that the salary ranges are mostly clustered at the lower end. From where, we interestingly have a linear line as well as a bunch of outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0AI5U5KJY7s",
        "colab_type": "text"
      },
      "source": [
        "#### Length Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-jl6ysGYPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8c027bd9-95c1-4a21-f4e5-dc0881ea11a1"
      },
      "source": [
        "word_length = fake_job_postings[['title', 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits', 'required_education', 'employment_type', 'required_experience', 'industry', 'function']].fillna('').astype(str).apply(lambda x:x.str.len())\n",
        "word_length.iloc[fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].index].mean() # Fake Average\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                    30.666282\n",
              "location                 14.872979\n",
              "department                5.058891\n",
              "company_profile         230.891455\n",
              "description            1154.834873\n",
              "requirements            446.049654\n",
              "benefits                212.196305\n",
              "required_education        9.382217\n",
              "employment_type           6.375289\n",
              "required_experience       6.144342\n",
              "industry                 12.158199\n",
              "function                  7.904157\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YEt0N1QJvlU",
        "colab_type": "text"
      },
      "source": [
        "The above are the average length for the fake jobs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jFgXDkaJTNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f822cee2-4e74-4dbf-d33b-f3d685c21c2d"
      },
      "source": [
        "word_length.iloc[fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].index].mean() # Real Average"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title                    28.421594\n",
              "location                 15.336311\n",
              "department                3.679558\n",
              "company_profile         640.752674\n",
              "description            1221.219701\n",
              "requirements            597.466146\n",
              "benefits                208.728165\n",
              "required_education        9.731339\n",
              "employment_type           7.154579\n",
              "required_experience       7.627718\n",
              "industry                 14.057952\n",
              "function                  8.367991\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObVC-ktSJuGx",
        "colab_type": "text"
      },
      "source": [
        "The above is the average character lengths for the real jobs. Most variables are about the same length but the biggest difference comes from the company profile and the requirements. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQY3T5SWKSrZ",
        "colab_type": "text"
      },
      "source": [
        "#### NLP Analysis of Longer text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGnK1qSETliv",
        "colab_type": "text"
      },
      "source": [
        "First, we need to get an understanding fo the text data and how it looks raw before designing a tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byh_Y-MBUVB4",
        "colab_type": "text"
      },
      "source": [
        "##### Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttg9TGWtSSUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "12e771dd-c145-4ef8-99fd-62e87caadaab"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].title.sample(10, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8027                                    Well Test Operator\n",
              "3194     Home Based Payroll Typist/Data Entry Clerks Po...\n",
              "17597                                 FRONT OFFICE MANAGER\n",
              "4967                            Military Benefits Advocate\n",
              "2483                        Customer Service Administrator\n",
              "17655                         Controls Engineer - Troy, MI\n",
              "6877                             Electrical Technician III\n",
              "11550                                         SEO Analysis\n",
              "5926                                  Assistant Accountant\n",
              "5870                             Receptionist Office Asst.\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd8JCaQ8UNvy",
        "colab_type": "text"
      },
      "source": [
        "This is the fradulent job titles. This sample looks mostly normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB8hCXcLT4-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "608aa020-7fb2-4b60-b534-e112400d9c57"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].title.sample(10, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13092    Sr. MS Dynamics Consultant ( AX or GP )\n",
              "13436                Software Engineer - Android\n",
              "17502                 TWIC or RAPIDGate Laborers\n",
              "10820               Agent-Inbound Sales Position\n",
              "2067               Internship (Media production)\n",
              "15735                          Executive Analyst\n",
              "2535                        Data Account Analyst\n",
              "6142              Cook / Assistant Cook - Meigle\n",
              "13695                             UX/UI Designer\n",
              "15945                             CNC Programmer\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAjteJ0yURn8",
        "colab_type": "text"
      },
      "source": [
        "This is the sample of the title for real jobs. This still looks normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keK-pFGpUXhG",
        "colab_type": "text"
      },
      "source": [
        "##### Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-b5AQz-UbVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ac3194fb-69e9-401a-e5f2-c24da3a4405f"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].location.sample(10, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8027          US, TX, Houston\n",
              "3194        US, AL, Abernant \n",
              "17597        US, OH, COLUMBUS\n",
              "4967                 US, IL, \n",
              "2483      US, CA, LOS ANGELES\n",
              "17655            US, MI, Troy\n",
              "6877          US, TX, Houston\n",
              "11550       US, CA, San Mateo\n",
              "5926                   AU, , \n",
              "5870     US, FL, Jacksonville\n",
              "Name: location, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgYJchhQUbp3",
        "colab_type": "text"
      },
      "source": [
        "The fraduluent locations seem normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE_dEZOXUb-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "07112654-1997-48b2-b578-ae24043a102b"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].location.sample(10, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13092                  EG, C, Maadi\n",
              "13436         US, CA, San Francisco\n",
              "17502              US, CT, Hartford\n",
              "10820     US, PA, Robinson Township\n",
              "2067                         GR, , \n",
              "15735               GB, LND, London\n",
              "2535                US, NJ, Hoboken\n",
              "6142     GB, PKN, Perth and Kinross\n",
              "13695                   KR, , Seoul\n",
              "15945           US, CA, Los Angeles\n",
              "Name: location, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbhEMFkFUchf",
        "colab_type": "text"
      },
      "source": [
        "The real job postings still look normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toBvSkuxUurP",
        "colab_type": "text"
      },
      "source": [
        "It seems that some cities are capitialized and some are not. Additionally, it looks like the job postings are intereational and thus, can be missing parts after the comma separation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BDffbeEU7Vg",
        "colab_type": "text"
      },
      "source": [
        "##### Department"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeRR9_4TVAUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "313f6c17-3d7d-4dfc-9918-ac54f3c621ae"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].dropna().department.sample(10, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5808      \\tCorporate Shared Services\n",
              "5838                    Oil & Energy \n",
              "8680                          Account\n",
              "4607                       CALLCENTER\n",
              "6505                         SECURITY\n",
              "8836                            MAINT\n",
              "937                 Refined Resources\n",
              "11739                    Oil & Energy\n",
              "6528                      CALLCENTER \n",
              "17813                Customer Service\n",
              "Name: department, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxs-4KDbVApN",
        "colab_type": "text"
      },
      "source": [
        "For the fake jobs, we do actually see a lot of energy related jobs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhD-xzH4VBC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "92f1419f-c48a-429d-e52a-6232d1b76537"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].dropna().department.sample(10, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13785                        Marketing \n",
              "11844                         Technical\n",
              "13906                       Development\n",
              "14599                             Sales\n",
              "12975                        Leadership\n",
              "298                               DTVMA\n",
              "776                               Sales\n",
              "9249     Sales and Business Development\n",
              "8010                                 IT\n",
              "12364               A Techstars Company\n",
              "Name: department, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7FCbOPVVBlI",
        "colab_type": "text"
      },
      "source": [
        "For the real jobs, it looks like real departments and then potentially misclassification as seen by the techstars company."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UroAPX2UZwkD",
        "colab_type": "text"
      },
      "source": [
        "##### Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOsi89NxZ-UW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "47fa6fac-3c09-440d-83a1-d1b0f9c71629"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].dropna().description.sample(1, random_state = 0).iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Act as a first point of contact for employee-related issues, conducting intake meetings with employees and/or managers who contact the Employee Relations Center of Excellence (COE) and helping to resolve concerns, address performance issues and work through escalated complaints or issues through providing coaching, mediation, consultation, corrective action and training. Provide advice, guidance and support to management and HR Business Partners, in partnership with the Employee Relations Leader, to efficiently address a wide array of employee conduct and performance-related issues, keeping appropriate parties apprised of the status and associated recommendations, as appropriate. Effectively develop and administer (in partnership with management) required corrective action and/or developmental action plans, as required. Partner with human resources and Legal leadership to design, cascade and promote standardized processes, templates, tools and/or technologies for use in managing employee relations activities, corrective action administration and escalated issue resolution protocols. Drive for consistent methodologies and practices that align with Novation vision around effective Employee Relations strategies. Provide training to further promote the Employee Relations COE and ensure consistency in approach across teams and business units whenever appropriate. Partner with human resources and cross functional partners (HR Business Partners, HR Operations, Legal, Compliance, business leadership, etc.) to proactively investigate and resolve escalated employee relations issues, as assigned. Gather detailed, pertinent information by conducting fact-finding interviews and investigations, interpreting the findings, preparing associated documentation, and meeting with management and the HR Business Partner to discuss possible action steps to resolve the issue. Partner with the Employee Relations Leader and Legal on employment law issues that are highly complex or that pose a risk to the company such as EEO complaints, lawsuits, complaint resolutions, understanding applicable law and potential liability. Ensure the Employee Relations database is updated on a regular and timely basis, providing thorough and detailed information surrounding the intake meeting(s), investigation procedures, resolution strategies, and associated next steps. Produce regular reports and metrics to help monitor trends in employment practices. Participate in the development and facilitation of training on a variety of employee relations topics including performance management, the performance improvement and corrective action processes, harassment, EEO regulations and other related ER topics. Provide HR coordinator support to the Escrow Services business, including assignment spanning the following categories: staffing and recruiting, reporting and dashboard development, exit interviews and associated trend analyses, meeting coordination, etc. Participate in special projects and perform other duties as required.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPGwiyVJaAb_",
        "colab_type": "text"
      },
      "source": [
        "This fake job posting looks almost normal. It does not name a company and references a department and seems to not be a finished job posting judging by the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAzE-5oOaIgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "e4be230e-64d5-4555-f32a-59269c28fbff"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].dropna().description.sample(1, random_state = 0).iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hayes Corporation is looking for a highly motivated, proactive Product Marketing Assistant with a passion in product marketing and management in mobile and social games.The ideal candidate will manage product advertisement and consumer perspective.The ideal candidate will be able to support multiple product lines through market research.ResponsibilitiesSupporting content publishing within in-game marketing channels. This includes a range of activities such as data entry, proofreading and product quality management.\\xa0Collaborate with design and content staff to ensure projects meet consumer objectives and expectations.Assist with various aspects of product marketing including advertising and pricing.Meet quick-to-market expectations.Support multiple product lines simultaneously.Research consumer opinions and marketing approaches to further improve product performance.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U2IT1Z3bH3t",
        "colab_type": "text"
      },
      "source": [
        "This real job posting names a company and the role name. The spacing is not perfectly parsed and there seems to be some special character encodings in this judging from the `\\xa0`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_eIizMWZyBq",
        "colab_type": "text"
      },
      "source": [
        "##### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvPo5kN6bZjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "7cf2b51e-e1a2-48b8-a996-93ecfd0bd9e7"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].dropna().requirements.sample(1, random_state = 0).iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Minimum of three (3) years of work Novationoffers an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. Novation is an Equal Employment Opportunity/Affirmative Action Employer and maintains a Drug-Free Workplace. We are fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences and values. Please apply on our website for #URL_9df44aa03d8a2708a5b7eb9f42cb8dfea4f5ee8bb3e37f676ad1d8031248b996# in an employee relations related field. Experience working in a shared services or COE model preferred. Knowledge of ER procedures and processes such as the proper handling of investigations, employee complaints and corrective actions. Technical understanding of employment laws and employee dispute resolution programs. Excellent written and verbal communication skills. Exceptional customer service focus and orientation. A high level of emotional intelligence and excellent interpersonal skills. Proven project management skills, including attention to detail and a demonstrated ability to manage multiple projects and tasks. Proven ability to multi-task in a high volume environment; ability to prioritize conflicting demands, and organize time and focus to bring investigations efficiently to successful completion. Ability to effectively engage with individuals at all levels of the organization. Demonstrated ability to influence and build collaborative relationships across divisions and geographies. Strong negotiation and conflict resolution skills. Ability to operate with a high degree of sensitivity and confidentiality. Ability to work independently and with minimal supervision. Proficient in Microsoft Office Suite (Word, Excel, PowerPoint). Ability and willingness to travel as needed; estimate up to 20%.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_U9JdPMbZ_1",
        "colab_type": "text"
      },
      "source": [
        "In this fake job posting, we can see that it looks mostly normal. There seems to be some spacing issues for parts of the sentence and it seems like the URLs have been stripped from this corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1tKvGBBbZQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dbee2364-08fe-4476-eaa9-b4c1bc4d9a05"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].dropna().requirements.sample(1, random_state = 0).iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Degree in any Business discipline, preferably MarketingStrong proofreading abilities, a keen eye for detailProficient in MS Office (Excel)Accurate data management, documentation and record-keeping skillsFluent English, both verbal and written. Chinese is helpful, although not necessaryAbility to multi-taskStrong interpersonal communication skills in a multicultural, cross-functional settingStrong understanding of mobile, social networking and gaming arenaResults oriented attitude'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL0jx_WbbacJ",
        "colab_type": "text"
      },
      "source": [
        "In this real requirement, we see that the spacing between bullets in the requirements is not implemented. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt9JlRd-ZzdP",
        "colab_type": "text"
      },
      "source": [
        "##### Benefits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNc0vDAQcQqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "48221634-9e68-409f-d6ad-c747eca6454c"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 1].dropna().benefits.sample(1, random_state = 0).iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Novation offers an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. Novation is an Equal Employment Opportunity/Affirmative Action Employer and maintains a Drug-Free Workplace. We are fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences and values. Please apply on our website for consideration.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kEQPAjYcRd1",
        "colab_type": "text"
      },
      "source": [
        "This fake benefit seems generic but makes sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5QIhrIHcRHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80c98997-878d-4a02-df00-007bcdd62a58"
      },
      "source": [
        "fake_job_postings[fake_job_postings[\"fraudulent\"] == 0].dropna().benefits.sample(1, random_state = 0).iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Full Medical after probation13 months discretionary bonus100% English environmentGet to play with the latest gadgets and technologies. eg Apple, Google, Twitter, mobile, Android, etc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNzbpzxucSC_",
        "colab_type": "text"
      },
      "source": [
        "This real benefit has new line or spacing issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snddeEuiiBr0",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and examination of Counts and TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeTl0JhYi8m3",
        "colab_type": "text"
      },
      "source": [
        "From the exploratory analysis, a tokenizer can be built. For now, we are only interested in alpha numeric characters. We can remove stop words, lemmatize the text, and remove some of the junk including the url,  emails, and any additional numbers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lkRQQ-PcREy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "def tokenizer(corpus, model = nlp):\n",
        "  \"\"\"\n",
        "  Tokenizer to keep alpha numeric, remove stop words, lemmatize text , remove url, remove emails, remove numbers\n",
        "  \"\"\"\n",
        "  bag_of_words = nlp(corpus)\n",
        "\n",
        "  parsed_words = [i.lemma_ for i in bag_of_words if not i.is_stop and i.is_alpha and not i.like_url and not i.like_num and not i.like_email]\n",
        "\n",
        "  return(parsed_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox5ofJAFeJZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1IBE90ckTBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_n_words(bag_of_words, vec, n=None):\n",
        "    \"\"\"\n",
        "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
        "    \"\"\"\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seSZ5XXFjNJw",
        "colab_type": "text"
      },
      "source": [
        "##### Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYVEcodCjeez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ccbcfd10-5fdb-44db-c9d3-ca4058b534e5"
      },
      "source": [
        "cv_title = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "cv1_title = cv_title.fit_transform(fake_job_postings.title)\n",
        "get_top_n_words(cv1_title, cv_title, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('manager', 2232),\n",
              " ('developer', 1828),\n",
              " ('engineer', 1620),\n",
              " ('sales', 1339),\n",
              " ('senior', 988)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmmaoLsBjNDL",
        "colab_type": "text"
      },
      "source": [
        "We can see the most frequent are management, and higher level roles. The two most popular direct roles are engineer and sales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F4XqoQrh95w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ba1e5167-c68c-4f6d-8d46-1311eac7b22b"
      },
      "source": [
        "tf_title = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "tf1_title = tf_title.fit_transform(fake_job_postings.title)\n",
        "get_top_n_words(tf1_title, tf_title, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('manager', 1514.7744028970876),\n",
              " ('developer', 1266.0328608377754),\n",
              " ('engineer', 1197.27209884887),\n",
              " ('sales', 914.7238336638629),\n",
              " ('senior', 652.0774215198769)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeVsR679lCku",
        "colab_type": "text"
      },
      "source": [
        "Using the tf-idf, we get similar results to count vectors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q0F0WrRmmc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79e7daf1-e767-4ced-f551-34b3ca9f6908"
      },
      "source": [
        "np.mean(cosine_similarity(tf1_title[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], tf1_title[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027120795983612972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEZCZiULndyL",
        "colab_type": "text"
      },
      "source": [
        "The above is the cosine similarity between the fradulent and non fradulent jobs using tf-idf. We get almost 0 which is good as we hope they are different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH5L3HN9lo05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a10c1107-7301-4ab6-e9c3-fdf3658a90ef"
      },
      "source": [
        "np.mean(cosine_similarity(cv1_title[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], cv1_title[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.029662819148400698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YSB9j0Fn1MB",
        "colab_type": "text"
      },
      "source": [
        "Similarly, when we do the average cosine similarity for counts we get almost 0 which means they are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuZ4QlxpoRe3",
        "colab_type": "text"
      },
      "source": [
        "##### Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi1nIZvXo9kS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa105e8d-9108-48e7-80ac-9b34875c2409"
      },
      "source": [
        "cv_location = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "cv1_location = cv_location.fit_transform(fake_job_postings.location.fillna(''))\n",
        "get_top_n_words(cv1_location, cv_location, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gb', 2384), ('ny', 1282), ('london', 1132), ('lnd', 992), ('tx', 975)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otX--XK4q-lR",
        "colab_type": "text"
      },
      "source": [
        "The jobs seem mostly located in potentially Great Britain and New York according to the count vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWNFcblno-Gt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "79c1a880-bc21-4d67-9452-5b75c2abff9f"
      },
      "source": [
        "tf_location = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "tf1_location = tf_location.fit_transform(fake_job_postings.location.fillna(''))\n",
        "get_top_n_words(tf1_location, tf_location, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gb', 1775.7610762409133),\n",
              " ('ny', 879.1788113958479),\n",
              " ('tx', 763.943191261618),\n",
              " ('london', 760.1820505886812),\n",
              " ('gr', 751.2959167755391)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udorZOaMrFhM",
        "colab_type": "text"
      },
      "source": [
        "According to tf-idf, we get very similar results to the tf-idf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCB34vH8o-ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9140d64-a042-43c5-d377-df80ee024d50"
      },
      "source": [
        "np.mean(cosine_similarity(tf1_location[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], tf1_location[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01955888139733028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QltXstWprPOy",
        "colab_type": "text"
      },
      "source": [
        "The mean cosine similarity between the fraduelent and non-fraudulent dataset is almost 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7uGiBWdo_ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "482321f8-3390-4cdd-e08d-ebc066623729"
      },
      "source": [
        "np.mean(cosine_similarity(cv1_location[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], cv1_location[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.020678388171154433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWcd3mxPrW-I",
        "colab_type": "text"
      },
      "source": [
        "The mean cosine similarity between the fraudulent and non-fraudulent dataset is almost 0 but a bit higher than the count vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_r3pBSroaeA",
        "colab_type": "text"
      },
      "source": [
        "##### Department"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvHTDqORpAsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ca6bd748-fc2a-4187-fdfa-637e6a083dc6"
      },
      "source": [
        "cv_department = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "cv1_department = cv_department.fit_transform(fake_job_postings.department.fillna(\"\"))\n",
        "get_top_n_words(cv1_department, cv_department, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sales', 683),\n",
              " ('engineering', 552),\n",
              " ('marketing', 529),\n",
              " ('operations', 330),\n",
              " ('development', 312)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtiSIWIHpI3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0d7b0c9d-0e55-471d-efaa-3fd5696df112"
      },
      "source": [
        "tf_department = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "tf1_department = tf_department.fit_transform(fake_job_postings.department.fillna(\"\"))\n",
        "get_top_n_words(tf1_department, tf_department, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sales', 666.6055261224266),\n",
              " ('engineering', 547.7048161503801),\n",
              " ('marketing', 517.4609667166276),\n",
              " ('operations', 328.55607485827863),\n",
              " ('development', 292.1341240034073)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g9pwhfdsEp3",
        "colab_type": "text"
      },
      "source": [
        "We can see that botht he tf-idf and count vectorizer finds the same top hits for department. It seems it is mostly sales and engieering related work that is hiring. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEczqjvIpJLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6de229f-f741-4096-8773-7e2f9cc7697d"
      },
      "source": [
        "np.mean(cosine_similarity(tf1_department[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], tf1_department[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003709763571489574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixpRQxNYpJhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d595e298-c7c4-40ff-aba5-634fd0a8d41f"
      },
      "source": [
        "np.mean(cosine_similarity(cv1_department[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], cv1_department[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003713573904059939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z3cFiQ2r5zL",
        "colab_type": "text"
      },
      "source": [
        "For both the TF-IDF and the count vectorizer, we can see that the mean cosine similarity between fraudulent and non-fraudulent job posts is almost 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbX6FwycoiW4",
        "colab_type": "text"
      },
      "source": [
        "##### Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYGNf2I4pBR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "df5be1c7-4bdd-4e9b-de54-d04e8c9d3a58"
      },
      "source": [
        "cv_description = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "cv1_description = cv_description.fit_transform(fake_job_postings.description.fillna(\"\"))\n",
        "get_top_n_words(cv1_description, cv_description, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('team', 17715),\n",
              " ('work', 14380),\n",
              " ('business', 10622),\n",
              " ('customer', 9775),\n",
              " ('new', 9735)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmERdkfNpKR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ebd082d1-7aa0-4c01-dcbf-1229f9ce7c0d"
      },
      "source": [
        "tf_description = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "tf1_description = tf_description.fit_transform(fake_job_postings.description.fillna(\"\"))\n",
        "get_top_n_words(tf1_description, tf_description, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('team', 691.9832712113662),\n",
              " ('work', 622.5833136797995),\n",
              " ('sales', 569.8148090500061),\n",
              " ('customer', 536.1533894811573),\n",
              " ('experience', 510.0660044225824)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3zyRQVPtsPi",
        "colab_type": "text"
      },
      "source": [
        "Comparing the count vectorizer with the tf-idf, we similar job description importance. Using the count vectorizer, we get the most common words being team and work related which is very generic. With tf-idf, we mostly get the same top 5 but also `experience`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92REdXx9pLGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43068370-a918-4dfb-f244-a66aa81b8832"
      },
      "source": [
        "np.mean(cosine_similarity(tf1_description[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], tf1_description[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04615427957813173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYFf4h36pLfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6350d2cd-2428-4d6f-b48e-ccad4d42c12b"
      },
      "source": [
        "np.mean(cosine_similarity(cv1_description[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], cv1_description[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07541392566933681"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykV38CzuuNs7",
        "colab_type": "text"
      },
      "source": [
        "As seen above, count vectorizer has 5% higher cosine similarity than TF-IDF which means TF-IDF does a better job of distinguishing fraudulent and non fraudulent posts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjmgMGPzolKe",
        "colab_type": "text"
      },
      "source": [
        "##### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2C7_2K0pCjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e8bf60f0-2017-44e3-efb0-604f53f59f3f"
      },
      "source": [
        "cv_requirements = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "cv1_requirements = cv_requirements.fit_transform(fake_job_postings.requirements.fillna(\"\"))\n",
        "get_top_n_words(cv1_requirements, cv_requirements, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('experience', 20634),\n",
              " ('skills', 10429),\n",
              " ('work', 9797),\n",
              " ('years', 7848),\n",
              " ('ability', 6961)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSqzANIpPw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "97eae034-bbdc-4274-c502-68f4bf08949e"
      },
      "source": [
        "tf_requirements = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "tf1_requirements = tf_requirements.fit_transform(fake_job_postings.requirements.fillna(\"\"))\n",
        "get_top_n_words(tf1_requirements, tf_requirements, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('experience', 1244.3437538115788),\n",
              " ('skills', 744.7890849017842),\n",
              " ('work', 730.014306420189),\n",
              " ('years', 631.3315410039722),\n",
              " ('ability', 543.8823383123708)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wiIue5nt_7k",
        "colab_type": "text"
      },
      "source": [
        "We get the same top words with both tf-idf and word counts. It seems the most important things people want are skills and experience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be8IAHuApQHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d55eeed2-73a4-47d1-ff2f-e2d813b5f9ce"
      },
      "source": [
        "np.mean(cosine_similarity(tf1_requirements[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], tf1_requirements[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03818614280236542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z15t186dpQjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bef20606-8103-4860-e445-d1a51a4d586e"
      },
      "source": [
        "np.mean(cosine_similarity(cv1_requirements[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], cv1_requirements[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07694572197518018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU2S6McQujya",
        "colab_type": "text"
      },
      "source": [
        "Similar to the job description cosine similarities, we see that the cosine similiarity of count vectorizer to be worse than TF-IDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX7_UkyAoomd",
        "colab_type": "text"
      },
      "source": [
        "##### Benefits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LeaL4DznZTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1e4afd0f-2e1d-445c-af6d-15a66f87eded"
      },
      "source": [
        "cv_benefits = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "cv1_benefits = cv_benefits.fit_transform(fake_job_postings.benefits.fillna(\"\"))\n",
        "get_top_n_words(cv1_benefits, cv_benefits, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('work', 4244),\n",
              " ('benefits', 3685),\n",
              " ('company', 3259),\n",
              " ('competitive', 2916),\n",
              " ('team', 2549)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEuDrBKzpRtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9c704773-642d-4159-98e2-a66fa3fd2f30"
      },
      "source": [
        "tf_benefits = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "tf1_benefits = tf_benefits.fit_transform(fake_job_postings.benefits.fillna(\"\"))\n",
        "get_top_n_words(tf1_benefits, tf_benefits, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('benefits', 665.4690645794257),\n",
              " ('job', 604.0228903001768),\n",
              " ('work', 586.6254547255782),\n",
              " ('description', 554.2962404038343),\n",
              " ('competitive', 527.0242344247309)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWDtEXPSvNYa",
        "colab_type": "text"
      },
      "source": [
        "For the benefits, we get relatively similar results between count vectorizer and tf-idf. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ1qOtbrpSJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21d01923-d96a-4b1d-e02d-8f49f51dd80b"
      },
      "source": [
        "np.mean(cosine_similarity(tf1_benefits[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], tf1_benefits[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019497645962743327"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKGd0tW7pSiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "531c44fc-5e09-41cc-b872-f66ae0909cdc"
      },
      "source": [
        "np.mean(cosine_similarity(cv1_benefits[fake_job_postings[fake_job_postings['fraudulent'] == 0].index], cv1_benefits[fake_job_postings[fake_job_postings['fraudulent'] == 1].index]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.026223827579902097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1NNCjgOvTI0",
        "colab_type": "text"
      },
      "source": [
        "We also get relatively similar results between the mean cosine similarity between TF-IDF and count vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ECmmvOzKIcs",
        "colab_type": "text"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vm_qtrKNUbx",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXSY60OmfUoY",
        "colab_type": "text"
      },
      "source": [
        "#### Salary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HUF93fFNXnx",
        "colab_type": "text"
      },
      "source": [
        "The salary range can be parsed out to use as numeric variables for our model. The salary range seems to include text variables so those need to be removed as well. The NaN values will be initialized at 0 as they are unknown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ehv56lSNk_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parse out the salary\n",
        "max_salary = []\n",
        "min_salary = []\n",
        "for salary in fake_job_postings.salary_range:\n",
        "  if pd.isnull(salary):\n",
        "    min_salary.append(0)\n",
        "    max_salary.append(0)\n",
        "  else:\n",
        "    salary_range = salary.split(\"-\")\n",
        "    if len(salary_range) > 1:\n",
        "      try:\n",
        "        min_salary.append(int(salary_range[0]))\n",
        "      except:\n",
        "        min_salary.append(0) # If text is input\n",
        "      try:\n",
        "        max_salary.append(int(salary_range[1]))\n",
        "      except:\n",
        "        max_salary.append(0) # If text is input\n",
        "    else: # In cases where input is just a single value\n",
        "      try:\n",
        "        min_salary.append(int(salary_range[0]))\n",
        "      except:\n",
        "        min_salary.append(0) # If text is input\n",
        "      try:\n",
        "        max_salary.append(int(salary_range[0]))\n",
        "      except:\n",
        "        max_salary.append(0) # If text is input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUy7ip7mRGix",
        "colab_type": "text"
      },
      "source": [
        "Next, the salaries need to be normalize as it's mostly 0s. The values are log 10ed in order to minimize the effects of 0 and because the numerical values if present are large."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnzOG--FRBil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "max_salary = [np.log10(i + 1) for i in max_salary]\n",
        "min_salary = [np.log10(i + 1) for i in min_salary]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M_DcWPuV0xI",
        "colab_type": "text"
      },
      "source": [
        "Then a basic histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPHw3CIiOU_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "978bbc7f-290f-4a04-e68d-88387bc653ce"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "axs[0].hist(min_salary, bins=5, label = \"Min. salary\")\n",
        "axs[1].hist(max_salary, bins=5, label = \"Max. salary\")\n",
        "plt.xlabel('Log10(Salary)')\n",
        "plt.ylabel('Count')\n",
        "axs[0].set_title('Minimum Salary Histogram')\n",
        "axs[1].set_title('Maximum Salary Histogram')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Maximum Salary Histogram')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXwjQEXvWe-w",
        "colab_type": "text"
      },
      "source": [
        "As we can see inthe plot above, most of the salaries are NaN or 0. It's very right skewed and there is a small peak again at around 4. It looks like there is a small increase in the maximum salary compared to the minimum salary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4ChEJjnfNae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add feature\n",
        "fake_job_postings[\"min_salary\"] = min_salary\n",
        "fake_job_postings[\"max_salary\"] = max_salary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTr5nMHDI5JJ",
        "colab_type": "text"
      },
      "source": [
        "#### Augmentation\n",
        "\n",
        "As there is a severe class imbalance, some text augmentation needs to be done to pad the number of fake jobs as we have a 1:19 classifier. The one hot encoding values can be the same but all of the text needs augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk_pPRHEI4oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "21af543b-56dc-42dc-bc9d-4669d5a663ea"
      },
      "source": [
        "# Use nlpaug as a way to augment text data\n",
        "# Install pre-reqs for nlpaug\n",
        "!pip install nlpaug\n",
        "!pip install torch>=1.2.0 transformers>=2.5.0\n",
        "!pip install nltk>=3.4.5\n",
        "!pip install pytorch-transformers\n",
        "\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "\n",
        "from nlpaug.util import Action"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.14\n",
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.91)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.30 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.30)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.30->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.30->boto3->pytorch-transformers) (2.8.1)\n",
            "Installing collected packages: pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axxwdBUTYJKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "96efd6d697fa462683b465d4baafa0a4",
            "15478d69707b47188aaeedf99eb01e6d",
            "c79ef4ce742a4bc39721ee9d87b22704",
            "e04ace75e8424c68ad82881741a5c965",
            "60e1bd8d48704d52af9d3bf27a4d12d6",
            "9e7d0bffcaff49ad88b9e6bdf72e1435",
            "76281635a37340079e55a0a06c6fc226",
            "a09af7fe13104c3fa49a37636924e576",
            "fda4e1e41d454782ae5ca53825ec75e4",
            "d0794745c81e465b9b87928f8f1ed7e5",
            "eae08f53bdf14d94b5b04f7362016288",
            "4b4554f11ceb43479e2468ab7c598834",
            "c4b8aa0bd1a940fa98a688437fb36d0a",
            "5eb385ab3c1e46739a1d44a67a745141",
            "dd5597199cc2495bacf4530e5a19a3ca",
            "5c00bd2c5e9e4a85ac7910e2429a1033",
            "e064e540c93a4858a9a2e9d975c78bf3",
            "93007d59281347328af70470390ded96",
            "05b8d35af91743c68f7849af688b4761",
            "af69f727978748f9a7d9efe68e6d18b6",
            "0988c258f8424db89e883c37bafe744d",
            "d7ddcb1ff71744189bf419ca86443e46",
            "5fc392ea13934784b1437a7940782c54",
            "bc4295a8730c462689c26b3e7662e7f9"
          ]
        },
        "outputId": "325257ba-101b-4bb9-df67-f040558c55c1"
      },
      "source": [
        "# Insertions\n",
        "aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")\n",
        "i_prof = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"company_profile\"]]\n",
        "i_descrip = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"description\"]]\n",
        "i_req = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"requirements\"]]\n",
        "i_benefits = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"benefits\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96efd6d697fa462683b465d4baafa0a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fda4e1e41d454782ae5ca53825ec75e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e064e540c93a4858a9a2e9d975c78bf3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n",
            "Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
            "If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
            "/usr/local/lib/python3.6/dist-packages/nlpaug/model/lang_models/language_models.py:103: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  num_sample = min(n, torch.nonzero(probas).size(0))  # Number of potential candidate is small when top_k/ top_p are used.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2IJexoBk0_f",
        "colab_type": "text"
      },
      "source": [
        "Insertions into the text is done using Bert. This is an artificial augmentation to add some additional context specific words to sound natural while ideally maintaining context. This is only done to the long text such as `company profile` as insertions don't make sense in some columns such as location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs3RnUm3Yi2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "1a49513f321f41c498f5f2ac3eca176d",
            "abb39cd87778403e8f6fe91ca54037dd",
            "e32f717b8365411498ef74d3497fcf5a",
            "3c487732e6154a9a8831adf53013c78d",
            "128bc49526414eebb2a9963d66ab64b4",
            "2a5022fd7499436b9c6e73d9d4e34cc1",
            "00f3c37fdaeb46e9857a7d59af9f98a5",
            "edbf1ffd821c437085972744febd5da9",
            "60185ddc58a249f7ab0590e71dd72c68",
            "9a5fac0dba1b4ca284adbc24124658de",
            "f6f351d143824e5a8080756a076b5465",
            "61c7097777cc4b8f9e8041d1ca002b39",
            "60001b655cec4216bc6399baa5155412",
            "a2646f07ada04488b01ad483bb63e7cf",
            "03717900d6354acf97a6b0b75fdaa19b",
            "a7a41db7ab5f440bbaad6aa74c4458cc"
          ]
        },
        "outputId": "8309fae1-eebb-4467-e06c-08f81471f4bb"
      },
      "source": [
        "# Substitution\n",
        "aug = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', action=\"substitute\")\n",
        "s_title = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"title\"]]\n",
        "s_department = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"department\"]]\n",
        "s_company_profile = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"company_profile\"]]\n",
        "s_description = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"description\"]]\n",
        "s_requirements = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"requirements\"]]\n",
        "s_benefits = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"benefits\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a49513f321f41c498f5f2ac3eca176d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60185ddc58a249f7ab0590e71dd72c68",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO6jqTp-rmnA",
        "colab_type": "text"
      },
      "source": [
        "We are interested in substituing the corpora. Assuming that the meaning is somewhat similar, it should not give us any detriments for augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpHuPOvkYrQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "247de769-ef83-4939-e562-2097892e4540"
      },
      "source": [
        "# Synonym\n",
        "## Download NLTK's synonym db\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "aug = naw.SynonymAug(aug_src='wordnet')\n",
        "sym_title = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"title\"]]\n",
        "sym_department = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"department\"]]\n",
        "sym_company_profile = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"company_profile\"]]\n",
        "sym_description = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"description\"]]\n",
        "sym_requirements = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"requirements\"]]\n",
        "sym_benefits = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"benefits\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXeftb9qs0oX",
        "colab_type": "text"
      },
      "source": [
        "This uses synonyms for words. This should be very similar to Bert's subsitutions and should work just as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3r0wSZPYzIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word Delete\n",
        "aug = naw.RandomWordAug()\n",
        "ws_title = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"title\"]]\n",
        "ws_department = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"department\"]]\n",
        "ws_company_profile = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"company_profile\"]]\n",
        "ws_description = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"description\"]]\n",
        "ws_requirements = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"requirements\"]]\n",
        "ws_benefits = [aug.augment(profile) if not pd.isnull(profile) else profile for profile in fake_job_postings[fake_job_postings[\"fraudulent\"] == 1][\"benefits\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2BT94VMtCKM",
        "colab_type": "text"
      },
      "source": [
        "Finally, the last augmentation that will be used is word deletion. This will delete some words in the documents which in theory, should help with overfitting with the extra noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N7yWz18tchX",
        "colab_type": "text"
      },
      "source": [
        "Now that we have some augmented words, we need to combine them into our dataset. The augmented datasets will be added in place along with the same variables in each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZSAT2Q-ogL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos1 = fake_job_postings[fake_job_postings[\"fraudulent\"] == 1]\n",
        "pos2 = fake_job_postings[fake_job_postings[\"fraudulent\"] == 1]\n",
        "pos3 = fake_job_postings[fake_job_postings[\"fraudulent\"] == 1]\n",
        "pos4 = fake_job_postings[fake_job_postings[\"fraudulent\"] == 1]\n",
        "\n",
        "# Insertions\n",
        "pos1[\"company_profile\"].replace(i_prof, inplace = True)\n",
        "pos1[\"description\"].replace(i_descrip, inplace = True)\n",
        "pos1[\"requirements\"].replace(i_req, inplace = True)\n",
        "pos1[\"benefits\"].replace(i_benefits, inplace = True)\n",
        "\n",
        "# Substitutions\n",
        "pos2[\"title\"].replace(s_title, inplace = True) \n",
        "pos2[\"department\"].replace(s_department, inplace = True) \n",
        "pos2[\"company_profile\"].replace(s_company_profile, inplace = True)\n",
        "pos2[\"description\"].replace(s_description, inplace = True)\n",
        "pos2[\"requirements\"].replace(s_requirements, inplace = True)\n",
        "pos2[\"benefits\"].replace(s_benefits, inplace = True)\n",
        "\n",
        "# Word Synonym\n",
        "pos3[\"title\"].replace(sym_title, inplace = True) \n",
        "pos3[\"department\"].replace(sym_department, inplace = True) \n",
        "pos3[\"company_profile\"].replace(sym_company_profile, inplace = True)\n",
        "pos3[\"description\"].replace(sym_description, inplace = True)\n",
        "pos3[\"requirements\"].replace(sym_requirements, inplace = True)\n",
        "pos3[\"benefits\"].replace(sym_benefits, inplace = True)\n",
        "\n",
        "# Add word deletion\n",
        "pos4[\"title\"].replace(ws_title, inplace = True) \n",
        "pos4[\"department\"].replace(ws_department, inplace = True) \n",
        "pos4[\"company_profile\"].replace(ws_company_profile, inplace = True)\n",
        "pos4[\"description\"].replace(ws_description, inplace = True)\n",
        "pos4[\"requirements\"].replace(ws_requirements, inplace = True)\n",
        "pos4[\"benefits\"].replace(ws_benefits, inplace = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIBdW4VvqKOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc36e1a7-9ec1-4ade-e3de-39575010ac7a"
      },
      "source": [
        "# Append augmented data\n",
        "augmented_data = fake_job_postings\n",
        "augmented_data = augmented_data.append(pos1)\n",
        "augmented_data = augmented_data.append(pos2)\n",
        "augmented_data = augmented_data.append(pos3)\n",
        "augmented_data = augmented_data.append(pos4)\n",
        "augmented_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21344, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzArCsQDtsVo",
        "colab_type": "text"
      },
      "source": [
        "After this exercise, we have about 4000 augmented documents to use. There is still the class imbalance but it is better as our fradulent jobs is now about 25% of the dataset. We can still do better and downsample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dW_IvD1gFqQ",
        "colab_type": "text"
      },
      "source": [
        "### More Feature Engineering\n",
        "\n",
        "#### Company Profile Text Length\n",
        "\n",
        "When we did the exploratory analysis earlier, we saw that one of the biggest differences between document length came from the company profile. We saw that the fake jobs were 3x shorter in profile description compared to real jobs. So how long the profile is might be useful for modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "535z5EZHgfN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_data[\"company_profile_length\"] = [len(i) if not pd.isnull(i) else 0 for i in augmented_data.company_profile]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEkBVD1F3wZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "augmented_data['Col1_scaled'] = scaler.fit_transform(augmented_data['company_profile_length'].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTaADQxgt_dt",
        "colab_type": "text"
      },
      "source": [
        "#### Downsampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7rSO2r6uCfx",
        "colab_type": "text"
      },
      "source": [
        "We have severe class imbalance. There is about 17000 real jobs and with augmentation, about 4500 fake jobs. We can hope to balance it out so models don't just choose the most frequent observation due to bayes rule. We will downsample the real jobs to keep 70% of those observations making the class balance about 2:1.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfFP54AEym23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "347adc2a-27c4-4c73-a216-1876d0e55ccb"
      },
      "source": [
        "downsampled_real_jobs = augmented_data[augmented_data[\"fraudulent\"] == 0].sample(frac = 0.7, random_state = 1) # 70% keep or about 11900\n",
        "downsampled_data = augmented_data[augmented_data[\"fraudulent\"] == 1].append(downsampled_real_jobs) # Add the downsampled to the actual\n",
        "downsampled_data.shape # Get the shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16240, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1FzhSl6zy8E",
        "colab_type": "text"
      },
      "source": [
        "Hopefully with this downsampling, there will be less bias in our models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxbHQWSgXOpr",
        "colab_type": "text"
      },
      "source": [
        "#### Train/Test Split\n",
        "\n",
        "The data needs to be train, validation, test split. As there are relatively few samples, the split will be the following 70%/20%/10%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSDByhYwXHRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q3qCfuT0f80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(downsampled_data, downsampled_data['fraudulent'], test_size=0.1, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.222, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEDWuM5K2IEG",
        "colab_type": "text"
      },
      "source": [
        "##### Shape Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUrD2dop17-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b9c0a71-e95e-4245-86ae-dfcb0369b0bb"
      },
      "source": [
        "x_train.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11371, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMiIJDTB1VsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f97fc78-e75b-4c71-9524-165f8c5300d5"
      },
      "source": [
        "x_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3245, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUEqIgpK1-OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51dc7103-4c82-4db0-dd74-f5390c016f32"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1624, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcKRkRgDyPD_",
        "colab_type": "text"
      },
      "source": [
        "### Non-NLP based models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLU6n88ZEJ-a",
        "colab_type": "text"
      },
      "source": [
        "This classification problem might not even be a NLP problem. Using the one hot encoded features or other features in the dataset, we might be able to classify not using more fancy or more computational methods. \n",
        "\n",
        "First, we can trying using a default parameter linear SVM with the one hot encoded variables to see how good of a model it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH-4hdlkwCEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USS81DRYwX4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "250696d1-5b33-469e-b1a3-a3a2e2c56618"
      },
      "source": [
        "svc = SVC(kernel=\"linear\")\n",
        "svc.fit(X = x_train[[\"telecommuting\", \"has_company_logo\",\"has_questions\"]], y = y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcQ7dW4JwbdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5b10a90-296f-4b3e-b292-789f96eb6740"
      },
      "source": [
        "svc.score(x_val[[\"telecommuting\", \"has_company_logo\",\"has_questions\"]], y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7882896764252696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXeO-iNU2A17",
        "colab_type": "text"
      },
      "source": [
        "It looks like a basic model with just the telecommuting status, company logo, and questions are sufficient for a relatively strong model. The accuracy is greater than 66% so even this model does do something.\n",
        "\n",
        "To ensure that this model has relatively strong accuracy, we also can get the f1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acFo7lTJPXmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d2d7d96-5913-4c66-a3b9-fce956ef479b"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_val, svc.predict(x_val[[\"telecommuting\", \"has_company_logo\",\"has_questions\"]]), average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7951598657941273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVH0oGZpx3OB",
        "colab_type": "text"
      },
      "source": [
        "We get a very reasonable F1 score which tells us the model is doing something in terms of precision and sensitivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sPVU6q8xwCS",
        "colab_type": "text"
      },
      "source": [
        "We can also try a length based model as it looks like there is a large company profile length difference and much lesser degree, benefits. It seemed like the average length for company profile was much shorter as it seemed like the fake job poster didn't want to put in any effort there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgJm7UHw0o7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0940abaf-c0fa-45ab-8cc3-c462123de2eb"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "rf.fit(X = x_train[[\"company_profile_length\"]], y = y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ZZO8E10qyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55d016df-18c4-48eb-bd6d-680b1fd5a29d"
      },
      "source": [
        "rf.score(x_val[[\"company_profile_length\"]], y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9519260400616333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au9wkfxz-42D",
        "colab_type": "text"
      },
      "source": [
        "We use a random forest as it seems like a simple tree based structure would be able to capture the differences in company profile length. We get a very high accuracy of 95.2%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXXpIeyo-t1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e82bc71-b609-4ebd-c7c7-bce4f349964d"
      },
      "source": [
        "f1_score(y_val, rf.predict(x_val[[\"company_profile_length\"]]), average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9508507927614245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ovWdKto_DbF",
        "colab_type": "text"
      },
      "source": [
        "When we also calculate the F1 score, we similarly get very high value which is indicative that that this random forest model has high sensitivity and specificity to this classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWko8PSV5lBU",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can also see how predictive using the salary variables are. We can use a simple logisitic model in the hopes of a probabilistic model based on salary ranges in a certain distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jP-Kqie_e4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "306d58a2-eaa5-43c6-9b06-282278ffd28a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=0)\n",
        "lr.fit(X = x_train[[\"min_salary\", \"max_salary\"]], y = y_train)\n",
        "lr.score(x_val[[\"min_salary\", \"max_salary\"]], y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7485362095531587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V17u2JWAAh9",
        "colab_type": "text"
      },
      "source": [
        "We get a worse accuracy score compared to the other models so far. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPWou-cq_kfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2585e22-da5d-42a7-d87f-2299bdb8978b"
      },
      "source": [
        "f1_score(y_val, lr.predict(x_val[[\"min_salary\", \"max_salary\"]]), average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6476812255173943"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-h9q7hyhOp-",
        "colab_type": "text"
      },
      "source": [
        "Finally, whem we get the f1 score, we can see that it performs pretty poorly. As this f1 score takes a weighted average, it's not immediately clear how it performs worse. We can create a confusion matrix to get a understanding of where it is doing poorly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT5PAVMmAdd8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59e8842f-95b8-413d-e3e1-4566e7f4f7c0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, lr.predict(x_val[[\"min_salary\", \"max_salary\"]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2415,   10],\n",
              "       [ 806,   14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg_4hAtFAopF",
        "colab_type": "text"
      },
      "source": [
        "From the above confusion matrix, we can see we have 806 entries that are majorly misclassified. As most of the values in the salaries are 0, it is reasonable to assume that logistic regression is not the best idea for predicting fradulent claims using just salary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izBmkcl6BaxA",
        "colab_type": "text"
      },
      "source": [
        "From the three different models above, we can see that the length of the company description is the most discriminating feature from our random forest model with accuracy of 95%. This will be our baseline moving forward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk6NaKca5nPw",
        "colab_type": "text"
      },
      "source": [
        "### NLP based models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjMHSVIQ_Uy4",
        "colab_type": "text"
      },
      "source": [
        "From here, we can see if more NLP focused models provide any benefits. We can start with simple word counts, move on to TF-IDF, and then do a simple topic model dimensionality reduction with linear SVM to see how well basic NLP models generalize to this prediction problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ttQuX4u5kTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "def tokenizer(corpus, model = nlp):\n",
        "  \"\"\"\n",
        "  Tokenizer to keep alpha numeric, remove stop words, lemmatize text , remove url, remove emails, remove numbers\n",
        "  \"\"\"\n",
        "  bag_of_words = nlp(corpus)\n",
        "\n",
        "  parsed_words = [i.lemma_ for i in bag_of_words if not i.is_stop and i.is_alpha and not i.like_url and not i.like_num and not i.like_email]\n",
        "\n",
        "  return(parsed_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3qbe-XN64Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYSBbh1rG9Zr",
        "colab_type": "text"
      },
      "source": [
        "#### Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H97NKua7I5lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cv_prediction(x_train, y_train, x_val, y_val, var):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_train: Training dataset\n",
        "  y_train: Predictor values for training\n",
        "  x_val: Validation/testing dataset\n",
        "  y_val: Predictor values for testing\n",
        "  var: Variable in training dataset to tokenize against\n",
        "\n",
        "  Outputs:\n",
        "  Prediction F1 Score\n",
        "  \"\"\"\n",
        "  cv = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "  cv1_model = cv.fit_transform(x_train[var].fillna(\"\"))\n",
        "  svc = SVC(kernel=\"linear\")\n",
        "  svc.fit(X = cv1_model, y = y_train)\n",
        "  return(f1_score(y_val, svc.predict(cv.transform(x_val[var].fillna(\"\"))), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdDnN3dOJ3_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fd587d8a-4fe1-46a1-8e3e-c2a6adac0aca"
      },
      "source": [
        "for i in [\"title\", \"location\", \"department\", \"company_profile\", \"description\", \"requirements\", \"benefits\", 'employment_type', 'required_experience', 'industry', 'function']:\n",
        "  print(\"F1 score for {}: \".format(i) + str(cv_prediction(x_train, y_train, x_val, y_val, i)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for title: 0.7752767235529788\n",
            "F1 score for location: 0.7550593442689499\n",
            "F1 score for department: 0.7895891137866691\n",
            "F1 score for company_profile: 0.962370188531064\n",
            "F1 score for description: 0.9572461619823535\n",
            "F1 score for requirements: 0.9138172319455837\n",
            "F1 score for benefits: 0.9067874635100966\n",
            "F1 score for employment_type: 0.6392278991149047\n",
            "F1 score for required_experience: 0.6392278991149047\n",
            "F1 score for industry: 0.7417278152928435\n",
            "F1 score for function: 0.6987479956234323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLbOxrzEN-p2",
        "colab_type": "text"
      },
      "source": [
        "The F1 scores for count vectorizer based linear SVM models for the text data is above. We can see that some models are okay and other models are not very strong predictors. For instance, the strongest models we have are the `company_profile`, `description`, `requirements`, `benefits`. The worst models come from `required_experience` and `function`. \n",
        "\n",
        "Our best model so far is the SVM for `company_profile` with F1 of `0.962` but even the description model performs better than our random forest of lenght of `company profile`. We can try TF-IDF next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Kb36y3PSIg",
        "colab_type": "text"
      },
      "source": [
        "#### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB8Qb5bT7C2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_prediction(x_train, y_train, x_val, y_val, var):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_train: Training dataset\n",
        "  y_train: Predictor values for training\n",
        "  x_val: Validation/testing dataset\n",
        "  y_val: Predictor values for testing\n",
        "  var: Variable in training dataset to tokenize against\n",
        "\n",
        "  Outputs:\n",
        "  Prediction F1 Score\n",
        "  \"\"\"\n",
        "  tfidf = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "  tfidf_model = tfidf.fit_transform(x_train[var].fillna(\"\"))\n",
        "  svc = SVC(kernel=\"linear\")\n",
        "  svc.fit(X = tfidf_model, y = y_train)\n",
        "  return(f1_score(y_val, svc.predict(tfidf.transform(x_val[var].fillna(\"\"))), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLVv4gAc7F11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f072c331-2695-4f77-c15f-14869229dc32"
      },
      "source": [
        "for i in [\"title\", \"location\", \"department\", \"company_profile\", \"description\", \"requirements\", \"benefits\", 'employment_type', 'required_experience', 'industry', 'function']:\n",
        "  print(\"F1 score for {}: \".format(i) + str(tf_idf_prediction(x_train, y_train, x_val, y_val, i)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for title: 0.7710426108128514\n",
            "F1 score for location: 0.7560926793978529\n",
            "F1 score for department: 0.7895891137866691\n",
            "F1 score for company_profile: 0.9626771519008811\n",
            "F1 score for description: 0.9401653192143011\n",
            "F1 score for requirements: 0.9028603648436896\n",
            "F1 score for benefits: 0.909310830299467\n",
            "F1 score for employment_type: 0.6392278991149047\n",
            "F1 score for required_experience: 0.6392278991149047\n",
            "F1 score for industry: 0.7417278152928435\n",
            "F1 score for function: 0.6987479956234323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YhD8x4G_qGV",
        "colab_type": "text"
      },
      "source": [
        "With TF-IDF, we get relatively similar results with the word counts. We still have the same large corpus data being the most discriminative of fradulent job postings. Other short text data like industry is not very informative of our model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRPV1DYjQXwA",
        "colab_type": "text"
      },
      "source": [
        "#### LDA\n",
        "\n",
        "Although we still get relatively good accuracy for some models, we should see if dimensionality reduction can further help the models. The number of components is arbitraily set to 5 but can be adjusted and tuned if the results look promising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDhymDMATEBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "def lda_prediction(x_train, y_train, x_val, y_val, var):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_train: Training dataset\n",
        "  y_train: Predictor values for training\n",
        "  x_val: Validation/testing dataset\n",
        "  y_val: Predictor values for testing\n",
        "  var: Variable in training dataset to tokenize against\n",
        "\n",
        "  Outputs:\n",
        "  Prediction F1 Score\n",
        "  \"\"\"\n",
        "  cv = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "  cv1_model = cv.fit_transform(x_train[var].fillna(\"\"))\n",
        "  lda = LatentDirichletAllocation(n_components=5)\n",
        "  lda_model = lda.fit_transform(cv1_model)\n",
        "  svc = SVC(kernel=\"linear\")\n",
        "  svc.fit(X = lda_model, y = y_train)\n",
        "  return(f1_score(y_val, svc.predict(lda.transform(cv.transform(x_val[var].fillna(\"\")))), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0Xm8AwTk6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fbb68bbd-1f0a-4d53-ae3f-380d4a475ec2"
      },
      "source": [
        "for i in [\"title\", \"location\", \"department\", \"company_profile\", \"description\", \"requirements\", \"benefits\", 'employment_type', 'required_experience', 'industry', 'function']:\n",
        "  print(\"F1 score for {}: \".format(i) + str(lda_prediction(x_train, y_train, x_val, y_val, i)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score for title: 0.6392278991149047\n",
            "F1 score for location: 0.6392278991149047\n",
            "F1 score for department: 0.7542025610757058\n",
            "F1 score for company_profile: 0.7314156623685575\n",
            "F1 score for description: 0.6392278991149047\n",
            "F1 score for requirements: 0.6392278991149047\n",
            "F1 score for benefits: 0.7100771718889073\n",
            "F1 score for employment_type: 0.6392278991149047\n",
            "F1 score for required_experience: 0.6392278991149047\n",
            "F1 score for industry: 0.6392278991149047\n",
            "F1 score for function: 0.6392278991149047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31uCk5byWa9K",
        "colab_type": "text"
      },
      "source": [
        "Look at the F1 scores for LDA with 5 topics, we can conclude that is is worse for all text data. Dimensionality reduction might be useful but will need to be heavily tuned to see if it can help with prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E76SlWFkW1en",
        "colab_type": "text"
      },
      "source": [
        "From NLP based models, we can see that either count based or TF-IDF based models around the `company_profile` and to lesser degrees, `description`, `requirements`, and `benefits` can work very well. Using TF-IDF or count based methods has better accuracy and likely, would generalize better against adversarial attacks as we aren't modeling off of length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDD43lJc_qlZ",
        "colab_type": "text"
      },
      "source": [
        "### Deep Learning based Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlgSGx7fZs3n",
        "colab_type": "text"
      },
      "source": [
        "We already get good performance using simplier models like random forest and SVM. We can see if the promises of deep learning can work with this relatively small dataset. We will use `simpletransformers` to simplify the huggingface transformer library api calls. We will specifically use roberta as it is reported to be better than Bert and with lower computational costs for training compared to other state of the art models like T5 or xlnet. The main advantages of these deep learning models is that although they are similiar to architecture in Bert, they are trained on a greater corpus and the thought is that transfer learning can perform zero shot learning on random tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UM153IF_s-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83a8929b-c64e-4254-cfea-e0278e3292c2"
      },
      "source": [
        "!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simpletransformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/f3/61752c4863166c52bce48ca3112cabe62ab7e9c470afab7339f3aefe9295/simpletransformers-0.45.5-py3-none-any.whl (200kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 28.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 184kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 194kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.18.5)\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 20.4MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/19/f8db9eff4b0173adf6dd2e8b0c3d8de0bfe10ec9ed63d247665980d82258/wandb-0.9.4-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.0.5)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.8.1rc1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2019.12.20)\n",
            "Collecting tqdm>=4.47.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/88/7b0ea5fa8192d1733dea459a9e3059afc87819cb4072c43263f2ec7ab768/tqdm-4.48.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->simpletransformers) (0.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (20.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.0.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (3.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (2.8.1)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.1.2)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/23/811fcdfc9d67fea7e47c91dd553081218d53dda744c28384f4d2f69206c9/sentry_sdk-0.16.3-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 47.9MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/a45320cab182bf1c8656107b3d4c042e659742822fc6bff150d769a984dd/GitPython-3.1.7-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.352.0)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (3.13)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (5.4.8)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.1MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->simpletransformers) (2018.9)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers) (2.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->simpletransformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers) (49.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n",
            "\u001b[?25hCollecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb->simpletransformers) (2.3)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.0.8)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: seqeval, gql, watchdog, subprocess32, graphql-core, pathtools\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=e305ca900b4ebdfe36eef8c6f37d9fd29597492ee0f64e37cb3f636281728cd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=b4d71db6105f05dfe140adde8223c38b928470efdf24fdb6a33d11f26ab33bde\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73870 sha256=8d36131486a933d4e3477236fe66da3ac1273b8024ea9d461ce2acd930c91d43\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=037c233e6d33792bcdd376c68c616df25fc31c4eefc5595edc39d0849c4bbbb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=0df554074990540160e00ad7a24cc605468442f557d7e7faebd996fda5fc0d3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=9f0459832791760cb7172f0d80b605f0bd066e87aa8754893dd14f7142c9964e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built seqeval gql watchdog subprocess32 graphql-core pathtools\n",
            "Installing collected packages: tensorboardx, sentry-sdk, smmap, gitdb, GitPython, graphql-core, gql, configparser, shortuuid, docker-pycreds, pathtools, watchdog, subprocess32, wandb, tqdm, seqeval, simpletransformers\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed GitPython-3.1.7 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.16.3 seqeval-0.0.12 shortuuid-1.0.1 simpletransformers-0.45.5 smmap-3.0.4 subprocess32-3.5.4 tensorboardx-2.1 tqdm-4.48.0 wandb-0.9.4 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osiXCApJS9W4",
        "colab_type": "text"
      },
      "source": [
        "Then we need to install apex to be more memory efficient with pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqS23_RtSn32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d6d261-1152-4542-a685-d53bf22a787d"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsrmu6N5SsON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbaa54ac-3bac-4f10-9819-b94aeca61122"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 7401 (delta 0), reused 0 (delta 0), pack-reused 7400\u001b[K\n",
            "Receiving objects: 100% (7401/7401), 13.89 MiB | 12.80 MiB/s, done.\n",
            "Resolving deltas: 100% (4998/4998), done.\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-3u8hk7fi\n",
            "Created temporary directory: /tmp/pip-req-tracker-15v4zmg9\n",
            "Created requirements tracker '/tmp/pip-req-tracker-15v4zmg9'\n",
            "Created temporary directory: /tmp/pip-install-dhgars5d\n",
            "Processing ./apex\n",
            "  Created temporary directory: /tmp/pip-req-build-sqxyv0z7\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-15v4zmg9'\n",
            "    Running setup.py (path:/tmp/pip-req-build-sqxyv0z7/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.6.0+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-sqxyv0z7/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-sqxyv0z7/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-sqxyv0z7/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-sqxyv0z7/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-sqxyv0z7/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-sqxyv0z7/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-sqxyv0z7/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-sqxyv0z7 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-15v4zmg9'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-3xs3opmi\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-sqxyv0z7/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-sqxyv0z7/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-3xs3opmi/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.6.0+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-sqxyv0z7/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:335: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/amp_C_frontend.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning:\n",
            "    Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
            "    The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
            "    If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "      warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/syncbn.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:150:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                            \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:152:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:66:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:150:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                            \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:152:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:66:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/record_function.h(18): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(126): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/record_function.h(18): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(126): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-3xs3opmi/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-sqxyv0z7\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-15v4zmg9'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyv4Res5TEt6",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will run some transformer models for our binary classification problem. We will use Roberta which was developed from Facebook and performs better than the base Bert models. We will only run the models on `company_profile`, `description`, `requirements`, and `benefits` as those are the features with the highest signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI45QOnbU2X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simpletransformer requires specific format to run\n",
        "train_df = x_train[[\"company_profile\", \"fraudulent\"]].fillna(\"\")\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "eval_df = x_val[[\"company_profile\", \"fraudulent\"]].fillna(\"\")\n",
        "eval_df.columns = [\"text\", \"labels\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YSOrD3ZQjit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "aaf28d4bd47b4ecca532bea8d1f8135c",
            "d8a4e744346d494ba4579b605a20f9a5",
            "c1ce8a105eb94397b8a4f1e5a10baeb0",
            "ea40f1ded2d34726a9a3eb799c11b6cd",
            "fcb2d2af01dc49768b1086767c551f49",
            "1c21a86432d34c919a25cf3521396260",
            "4a23df5efa314a71937b99f4c62b1c4a",
            "f5d9bea3beb845b3be717e827414b54a",
            "2e55a819618d4d83b7652e7147db995e",
            "4da1e463bed44960a98410ff7d4eecc6",
            "ea3fd52677374fcc9eeaf972c56b419f",
            "4781e45dfe9240acb5c5ceacdc1ddbfd",
            "a12506c486b1412bae0feca9882756f1",
            "eea29323922e4d65be5473671f05ea4f",
            "853252f5aa1e4bc0bc3e847902286cfe",
            "8456f8b640a948cca54010ef0d4872e5",
            "5e7172a7ef404c858876062ca473c959",
            "0f1a850fe7534d409961b6db520d86f7",
            "227f10ba6ac44744b8fc95508e0760dc",
            "6859565133934e9599e4f5b7c15aa667",
            "959b89ad45714449b733c143d00c191a",
            "28f17d77cacc415891d9679875efadb3",
            "6ea51c2a5ea74b7fbc98d6c970497dd7",
            "1bf6b0b3371c4a029bb4e8d62cd35553",
            "2063fcb80d1740c682a1edc437d7574c",
            "a17841d1d94e4bc9805000f4e5fbaa97",
            "20d57dbcfe504bbdb786120bc225aea7",
            "758f1e4e2ab14130b311ba073636bbe3",
            "d5bc65a9fc65423283300b365eec689b",
            "a79efa61a3f74fd2862009e30d171188",
            "b905ab4f5c65438fbbe215438b3d108b",
            "92b5d57d720b419586ee895a6f42115b",
            "c6e591904d7e47a7ab585215c92dc00e",
            "d15f18a3f9414930922798e455e73854",
            "7b1a0ef0993a409d9ef6de85a3eb0ced",
            "4d3b880875764ac1bd1bfaea75379723",
            "cc431254d84940fe8ca81479048e4562",
            "87d38a7472674b9f9d5b588194465e60",
            "3bc18c266b224b798156f298b778bcb0",
            "83e5bb9e8ad945bf9544b256fdd20fc3",
            "02b38f1ef06a4c619ef50c2401c82cac",
            "e6f9195443af48a98a0f2360d47a5810",
            "a1ba1b1386494ebc8fceeb2cf44bc2b8",
            "d3c33c4039c543d0afaaff52a35a664e",
            "8547862659fb4579aec7b9f960dd3069",
            "24395d6a83534c858763dbf0e1c8369f",
            "9e9f3a2fb2dd49e8b801653f5f451d29",
            "4913a791591f4101a7a27c532d56dcd7",
            "4a16ce5b12e649c1b3349d0dbd57d0b4",
            "492612668ef34ee592619f49a8f7167a",
            "a3279f5f73cb42698c86f6b13d42cc1a",
            "b583bdd7312c4d7695a2ea5c344b4204",
            "95babaf4a6d54b888031035e572053a6",
            "96ff97755505486c9f382c03e78c4a3e",
            "41f21ffccda540988f2703a0889f5fe7",
            "89523cef250c453190828fe4c0aeca89",
            "06a0778e71d34e4095e77e6f8b9039c5",
            "6db060188fbf4a5fa906cb080ef8601a",
            "4232dccd243e4eb9898626b58e5254f6",
            "82a7a6089f4447d59d357ba359702ec9",
            "aceeb7e180514eeabf19d0cb8482b545",
            "0683ab514cff4754b5b7f62ddc7b511b",
            "5a5eb95877154cd4b1dc52c5d3c93dae",
            "f86fca4b5adf4156b5e7a3f51bb86eef",
            "f3e4c2eeb180407ea2505baa67ba8aa4",
            "1aa58436b3e9401499d5ac5784e26af1",
            "b9daf0c2278e476db86939b2bf653f03",
            "5ab75e0c53b942a6b8cbd833df1d985e",
            "03385e2f667249cf961a903fe469b48d",
            "da0b69689980431f82bac4d29cde73c1",
            "951e19c808224781ac93dbe520307d8c",
            "6a02db8cfebb440587e6305cc9b26796",
            "c8819480b58b472a8e5bcb99c46574bf",
            "e27248153cb140a2a92ae86d40c4a1b4",
            "d3b603ffde234ee092577a5a76993319",
            "7f5ad022118c490886313c08120faea6",
            "4a9d05b1f9cb43a79bb9cb18b8532c93",
            "87401e6387cd4bf39185953e54e7fde5",
            "84fd97c13b3649d483d8b5e7a21e1c85",
            "e6d8cf7c53a94f04a649ebf2b6bdbd6a",
            "756fd766ed884b34826a5892b5969ac6"
          ]
        },
        "outputId": "9688a470-20c9-4d66-d611-278231615cc4"
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Base model arguments\n",
        "model_args = {\"overwrite_output_dir\": True,\n",
        "              \"manual_seed\": 1, # Seed to reproducibility\n",
        "              \"num_train_epochs\": 3, # Number of epochs for training\n",
        "              \"learning_rate\": 0.00001, # Learning rate for gradients\n",
        "              \"use_early_stopping\": True, # Stop early in case of no improvements to speed things up\n",
        "              \"weight_decay\": 0} # L2 regularizer to deal with overfitting\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', args = model_args) # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556036370328 acquired on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaf28d4bd47b4ecca532bea8d1f8135c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556036370328 released on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n",
            "INFO:filelock:Lock 140556036422512 acquired on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e55a819618d4d83b7652e7147db995e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556036422512 released on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:filelock:Lock 140556036422792 acquired on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e7172a7ef404c858876062ca473c959",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556036422792 released on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556035638440 acquired on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2063fcb80d1740c682a1edc437d7574c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556035638440 released on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6e591904d7e47a7ab585215c92dc00e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11371.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02b38f1ef06a4c619ef50c2401c82cac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a16ce5b12e649c1b3349d0dbd57d0b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06a0778e71d34e4095e77e6f8b9039c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3e4c2eeb180407ea2505baa67ba8aa4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8819480b58b472a8e5bcb99c46574bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3245.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "756fd766ed884b34826a5892b5969ac6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=406.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model:{'mcc': 0.902557458520296, 'tp': 703, 'tn': 2423, 'fp': 2, 'fn': 117, 'eval_loss': 0.0990929758063251}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C28YZW6X9P0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2974459e-a675-4b5b-9c18-b1a4d6150126"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.0990929758063251,\n",
              " 'fn': 117,\n",
              " 'fp': 2,\n",
              " 'mcc': 0.902557458520296,\n",
              " 'tn': 2423,\n",
              " 'tp': 703}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t5ouyls_tcl",
        "colab_type": "text"
      },
      "source": [
        "Looking at the roberta model for the company profile, we get worse accuracy than the random forest and worse than the simple word count of tf-idf SVM model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5v7rqAxmIVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "cab3d997471f43178a13d528133221bc",
            "7d1c533db2ad453f8428ea7d1d63e03c",
            "38fd870d97ad4d0b98589c585f760946",
            "065f0e59380e4b888bda393d784ad731",
            "f05ccbcccf7946afb046a3021b5d0706",
            "8470564f001d4334bd8853452b480a48",
            "1dcd7bc18f844882bce7dd396a7f4b65",
            "d7a46aebff4647e39e0b35c563922450",
            "e9fc0b0554b745cd8c25c16927c1f92b",
            "95705971e152417ebe64500614455795"
          ]
        },
        "outputId": "627e232a-40ce-4eb6-ed3b-6fc566cb531e"
      },
      "source": [
        "# Simpletransformer requires specific format to run\n",
        "train_df = x_train[[\"description\", \"fraudulent\"]].fillna(\"\")\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "eval_df = x_val[[\"description\", \"fraudulent\"]].fillna(\"\")\n",
        "eval_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Base model arguments\n",
        "model_args = {\"overwrite_output_dir\": True,\n",
        "              \"manual_seed\": 1, # Seed to reproducibility\n",
        "              \"num_train_epochs\": 3, # Number of epochs for training\n",
        "              \"learning_rate\": 0.00001, # Learning rate for gradients\n",
        "              \"use_early_stopping\": True, # Stop early in case of no improvements to speed things up\n",
        "              \"weight_decay\": 0} # L2 regularizer to deal with overfitting\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', args = model_args) # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cab3d997471f43178a13d528133221bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11371.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f05ccbcccf7946afb046a3021b5d0706",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8470564f001d4334bd8853452b480a48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dcd7bc18f844882bce7dd396a7f4b65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7a46aebff4647e39e0b35c563922450",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9fc0b0554b745cd8c25c16927c1f92b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3245.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95705971e152417ebe64500614455795",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=406.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model:{'mcc': 0.958478719372674, 'tp': 797, 'tn': 2397, 'fp': 28, 'fn': 23, 'eval_loss': 0.10796387385315101}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'mcc': 0.958478719372674, 'tp': 797, 'tn': 2397, 'fp': 28, 'fn': 23, 'eval_loss': 0.10796387385315101}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foe1hn-mVeV",
        "colab_type": "text"
      },
      "source": [
        "When trained and predicting using the `description` column, we actually get marginally better results than the best model being the simple count vectorizer SVM model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiZ4hEkZmWC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "419ddca79bf744c79006a394e2aa6fc9",
            "84bd245c28bb4b618646174aaa16a7b0",
            "05489e4efd5d4a048119fa5014ca3e05",
            "efc11471d33e43d9ba4db037935e0957",
            "6af6d04d7f0a4cd2b0842f05892a2c27",
            "474f0ac3394d40bdbe2d6b474fb42e62",
            "c7e77a8615ae478ebfb080d23abd55ac",
            "a8e8bd418d2644e68c5ce64aac2decc8",
            "476bc01abd6d4b6e8fd42e8e033393cf",
            "c319fce527a04c18b28e0a5299b87c2d",
            "2140390f82b940ed984a86d42da60ab6",
            "b9b11141a3cb4108b3b6f702727b6073",
            "67f78432c9d047299f6fca2961ce4c12",
            "a38e94159c354f1a8b08a72ec787ffb2",
            "08ba6618fbe94c3195e3777c46fb5b64",
            "55c64ec5f4674b728d3b9362cd54cee9",
            "8ba69ca221fa4be7ad9b934f095b018f",
            "47e2451a184d4e5d8a0fa8c88f547056",
            "de455c66161b4915b42f6bae5f1f1bd2",
            "6285542ac45b40d785a10959a2da89c5",
            "53405648006541788b4b64179f74e280",
            "c0b4b5b0872a471b9e605d5357245b06",
            "c9737aa17ab944b7afb3225dac806373",
            "7fcc9a9774904b4ea2adad78603df103",
            "62e723fd0d2d43d9a831204b644f1936",
            "3aca46efb7084f208ca781fdfb5865f7",
            "159e18b6e493454d92880b2f284f2ca0",
            "3ba0cfb77ed540f08e08831ed6e4ae59",
            "cb21e36635c54e5b90e230da44ecbf39",
            "48c88869a5e4451fb8e26a22cc9594f7",
            "0405444d985b4d1c80f03eb757958355",
            "893cf12b9f3848a480b30026ec7dfd7a",
            "a6e5926d753f44fa8f0734e233851d08",
            "a4244170011e4e889e5f0a9c9748ac3d",
            "823e0d511a0149888a97ab431d85bc6a",
            "f4c67b3312be48b98f3fe8fa0cd86703",
            "689191f7088e4bad95bc433575f49ef1",
            "3db057fec0be44f39041726c4ea731ba",
            "0eedd2cbe42444efbdaaa65059310891",
            "1ec4261bdc8f4088bc812408449d43fa",
            "c87830f93138478795c7ca0dacc89105",
            "411edeca8880453dbb4fe6caf9daac38"
          ]
        },
        "outputId": "a334bfb3-06f7-4b73-8f2b-b4a48d800735"
      },
      "source": [
        "# Simpletransformer requires specific format to run\n",
        "train_df = x_train[[\"requirements\", \"fraudulent\"]].fillna(\"\")\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "eval_df = x_val[[\"requirements\", \"fraudulent\"]].fillna(\"\")\n",
        "eval_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Base model arguments\n",
        "model_args = {\"overwrite_output_dir\": True,\n",
        "              \"manual_seed\": 1, # Seed to reproducibility\n",
        "              \"num_train_epochs\": 3, # Number of epochs for training\n",
        "              \"learning_rate\": 0.00001, # Learning rate for gradients\n",
        "              \"use_early_stopping\": True, # Stop early in case of no improvements to speed things up\n",
        "              \"weight_decay\": 0} # L2 regularizer to deal with overfitting\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', args = model_args) # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "419ddca79bf744c79006a394e2aa6fc9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11371.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476bc01abd6d4b6e8fd42e8e033393cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ba69ca221fa4be7ad9b934f095b018f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62e723fd0d2d43d9a831204b644f1936",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6e5926d753f44fa8f0734e233851d08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c87830f93138478795c7ca0dacc89105",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3245.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "411edeca8880453dbb4fe6caf9daac38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=406.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9120251661367399, 'tp': 768, 'tn': 2369, 'fp': 56, 'fn': 52, 'eval_loss': 0.16394569324756733}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'mcc': 0.9120251661367399, 'tp': 768, 'tn': 2369, 'fp': 56, 'fn': 52, 'eval_loss': 0.16394569324756733}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHbyx_BxmXaF",
        "colab_type": "text"
      },
      "source": [
        "This model using the requirements as the parameter gets comparable accuracy as the tf-idf SVM model and count vector model. There is still room for improvement as heavy hyperparamter tuning has not been done but it might not be worth additional training complexity when we can tune the SVM models instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf78Bx1UmX4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "11d6e9aa03db4748836608f1adbe04c8",
            "19d0dab2aa304d6fa8adf5b0724c315b",
            "7775b49d68354935af18679123ffc30e",
            "a5a54469f2224b7481307b39ac8da6df",
            "047b7ab9b6444d58a49890018d4c0cef",
            "8a63d22912f44dc9a302a57b1e726c7d",
            "d76c0308ab1e44a28cd0b4319bdfc522",
            "784b7a19e5d34b008cbaa5f8ee2451d3",
            "60da1bed6d0b480684b8a9e5088bca24",
            "8c4d6e34835746d5a1ba7507e06ef39a",
            "1a416e19247a4048b34ea9c01ab14d56",
            "4de1adfa48994e9a8710280f0a68e4c1",
            "6f84f218c4f84fcba4885597a02e4c2d",
            "ebe6a8f2eca6483cbf50463a91bdbea5",
            "56da9191c8334023851101439faf4592",
            "2b05e34cb63842998b38c85521865f29",
            "3983cf578f984b16b9f63bfaf0376b24",
            "48cbc52d5da54e5a9a30ac8929c43fe7",
            "4b9d50f9dd654a068993feebdc834aa5",
            "602d3ba1d2964da4980cc85bf1c63d87",
            "585b7e77f0a648b8b5d24ee6f8d3916a",
            "8fa915d03ca54579bf567be29b417c3c",
            "217ca733bc014e52910f1c5a1f9c8751",
            "42219849e6d24405881856e8497c47a7",
            "b2ffcb62f25f4781aceb12aff3252516",
            "d21b3fc80fad4356af2cd2d75acb1234",
            "dcfc5c07c07342f7b8f8d0d3f10df0fe",
            "1c741d0e93c14fa6acbb157b255913e3",
            "4b35844e0c364c0c928c2ad65c776d51",
            "a3c3d92709f6453cac8c10566a7804bd",
            "598493208af745be9f9d595b23111dd1",
            "40de99e4f0614d27a9d0ef668f4bd505",
            "d4ae925e0d9b448593952b0ac41d4757",
            "342aa6a9dbec4e429f44d676bbe4af96",
            "6dab567834f047688c718cf9388f195a",
            "f8ca2529c24e4c8ab07ea39bc8c13e32",
            "54a1f558b2d64cdfa2de91d4b855add4",
            "25e0c43b55ae466b9a9a16b525e05eca",
            "f062865bf6894eb2a5399036d7190b50",
            "05fadf3a2a7242c7aa748cfe27433fa1",
            "2c2c372780ec40a19b392f6d1b906482",
            "43ce1944ef004f05a72932c6a97802ea",
            "58dddad57ba34c538bb79e45a375fbe5",
            "c0acf6753b6d49f9a73f2e61ac343239",
            "c8036104d71649b3824c03cd0266be51"
          ]
        },
        "outputId": "a783ca0c-8895-4b28-a659-a71992c394ae"
      },
      "source": [
        "# Simpletransformer requires specific format to run\n",
        "train_df = x_train[[\"benefits\", \"fraudulent\"]].fillna(\"\")\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "eval_df = x_val[[\"benefits\", \"fraudulent\"]].fillna(\"\")\n",
        "eval_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Base model arguments\n",
        "model_args = {\"overwrite_output_dir\": True,\n",
        "              \"manual_seed\": 1, # Seed to reproducibility\n",
        "              \"num_train_epochs\": 3, # Number of epochs for training\n",
        "              \"learning_rate\": 0.00001, # Learning rate for gradients\n",
        "              \"use_early_stopping\": True, # Stop early in case of no improvements to speed things up\n",
        "              \"weight_decay\": 0} # L2 regularizer to deal with overfitting\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', args = model_args) # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11d6e9aa03db4748836608f1adbe04c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11371.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60da1bed6d0b480684b8a9e5088bca24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3983cf578f984b16b9f63bfaf0376b24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2ffcb62f25f4781aceb12aff3252516",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4ae925e0d9b448593952b0ac41d4757",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c2c372780ec40a19b392f6d1b906482",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3245.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8036104d71649b3824c03cd0266be51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=406.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9134727161203707, 'tp': 730, 'tn': 2410, 'fp': 15, 'fn': 90, 'eval_loss': 0.16407332095287291}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'mcc': 0.9134727161203707, 'tp': 730, 'tn': 2410, 'fp': 15, 'fn': 90, 'eval_loss': 0.16407332095287291}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytxY00OWmYhC",
        "colab_type": "text"
      },
      "source": [
        "With benefits, we get the strongest performance using that metric yet by about 0.4%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmqI7az6meq6",
        "colab_type": "text"
      },
      "source": [
        "Using the Roberta architecture for our prediction problem, we get relatively good accuracy for all of the different parameters we have chosen. Only job description and the benefits have marginal improvements compared to using simplier models like SVM. The other parameters performed worse than their count and tf-idf SVM based counterpart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI7oyDHwAl3x",
        "colab_type": "text"
      },
      "source": [
        "### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJfJXEeVUq48",
        "colab_type": "text"
      },
      "source": [
        "In our modeling, we have seen that simple non NLP based approaches could work. Basic NLP models also seem to work very well in the classifcation problem and although state of the art neural network models do work well, they do not do better than the simplier models. \n",
        "\n",
        "Now that we have run 3 completely different modeling ideas, we can finally run them against the test set data and see how it performs. The highest accuracy that we have gotten was from `company_profile` and  `description` respectively. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgFKexQC2SuK",
        "colab_type": "text"
      },
      "source": [
        "#### Company Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q_yEV_kUpoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "rf.fit(X = x_train[[\"company_profile_length\"]], y = y_train)\n",
        "rf_cp_score = rf.score(X = x_test[[\"company_profile_length\"]], y = y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0i5d9YM3U6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified function to return base accuracy score\n",
        "def cv_prediction_score(x_train, y_train, x_val, y_val, var):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_train: Training dataset\n",
        "  y_train: Predictor values for training\n",
        "  x_val: Validation/testing dataset\n",
        "  y_val: Predictor values for testing\n",
        "  var: Variable in training dataset to tokenize against\n",
        "\n",
        "  Outputs:\n",
        "  Prediction F1 Score\n",
        "  \"\"\"\n",
        "  cv = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "  cv1_model = cv.fit_transform(x_train[var].fillna(\"\"))\n",
        "  x_val_tokenized = cv.transform(x_val[var].fillna(\"\"))\n",
        "  svc = SVC(kernel=\"linear\")\n",
        "  svc.fit(X = cv1_model, y = y_train)\n",
        "  return(svc.score(X = x_val_tokenized, y = y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yrp4QxL320O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CV SVM\n",
        "cv_cp_score = cv_prediction_score(x_train, y_train, x_test, y_test, \"company_profile\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gflaEsEM5cQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "3f8a840e31c245b7a05a0a9295faa4ad",
            "b08fb42397f54a9caeb13aec6080eba9",
            "73c335d6c2d54a209204d8ac34d285c3",
            "bd5d3743a3ba44b28cc79f46145eb486",
            "e8e26318e01641d5abb543a2366cda1b",
            "94728d68d4414643a2a083f8618f19cb",
            "0f47cbeeeb6f488c970c04e422e66829"
          ]
        },
        "outputId": "6b3b5aa7-3600-45eb-a8ed-c4e6f2ad6066"
      },
      "source": [
        "# Simpletransformer requires specific format to run\n",
        "train_df = x_train[[\"company_profile\", \"fraudulent\"]].fillna(\"\")\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "eval_df = x_test[[\"company_profile\", \"fraudulent\"]].fillna(\"\")\n",
        "eval_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Base model arguments\n",
        "model_args = {\"overwrite_output_dir\": True,\n",
        "              \"manual_seed\": 1, # Seed to reproducibility\n",
        "              \"num_train_epochs\": 3, # Number of epochs for training\n",
        "              \"learning_rate\": 0.00001, # Learning rate for gradients\n",
        "              \"use_early_stopping\": True, # Stop early in case of no improvements to speed things up\n",
        "              \"weight_decay\": 0} # L2 regularizer to deal with overfitting\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', args = model_args) # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "roberta_cp_mcc = result['mcc']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f8a840e31c245b7a05a0a9295faa4ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11371.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b08fb42397f54a9caeb13aec6080eba9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73c335d6c2d54a209204d8ac34d285c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd5d3743a3ba44b28cc79f46145eb486",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e26318e01641d5abb543a2366cda1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=1422.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94728d68d4414643a2a083f8618f19cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1624.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f47cbeeeb6f488c970c04e422e66829",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=203.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9116992428851923, 'tp': 388, 'tn': 1179, 'fp': 1, 'fn': 56, 'eval_loss': 0.09577619878177644}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZTjX3Cp9nz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe049fc5-8090-43fb-e2a2-399406ac2cdc"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "x = ['Random Forest Lengths', 'Count SVM', 'Roberta']\n",
        "y = [rf_cp_score,cv_cp_score,roberta_cp_mcc]\n",
        "ax.bar(x,y)\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model vs Accuracy for Company Profile\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et-Vijt19scs",
        "colab_type": "text"
      },
      "source": [
        "As can be seen in the plot above, all three models do a very good job of classifying fradulent jobs. Using the count vectorizer and SVM, we get the best performance. The worst would be using Roberta in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NJF2z-g2X5A",
        "colab_type": "text"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7lAVClm2ZXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CV SVM\n",
        "cv_desc_score = cv_prediction_score(x_train, y_train, x_test, y_test, \"description\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGc7yhs-9MMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "8d42cc029ba6429eb00ba7758cef281f",
            "06827878e06b4fe8acccd8ad3f2de04b",
            "1fb8919f70b14d7ba71d9f569281b131",
            "855d87d3285c49518c9aed0cd0319dc5",
            "c7672e6d3d84438d9ff35ddf811373d6",
            "1920622701d2410d81c0e9a0600d2dac",
            "54465fc36759463199e31c04b9b72afb"
          ]
        },
        "outputId": "1b42e4cf-8671-4875-fe16-47ac26c85ec6"
      },
      "source": [
        "# Simpletransformer requires specific format to run\n",
        "train_df = x_train[[\"description\", \"fraudulent\"]].fillna(\"\")\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "eval_df = x_test[[\"description\", \"fraudulent\"]].fillna(\"\")\n",
        "eval_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Base model arguments\n",
        "model_args = {\"overwrite_output_dir\": True,\n",
        "              \"manual_seed\": 1, # Seed to reproducibility\n",
        "              \"num_train_epochs\": 3, # Number of epochs for training\n",
        "              \"learning_rate\": 0.00001, # Learning rate for gradients\n",
        "              \"use_early_stopping\": True, # Stop early in case of no improvements to speed things up\n",
        "              \"train_batch_size\": 4,\n",
        "              \"weight_decay\": 0} # L2 regularizer to deal with overfitting\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', args = model_args) # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
        "roberta_desc_mcc = result['mcc']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_utils:Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d42cc029ba6429eb00ba7758cef281f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11371.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06827878e06b4fe8acccd8ad3f2de04b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fb8919f70b14d7ba71d9f569281b131",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=2843.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "855d87d3285c49518c9aed0cd0319dc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=2843.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7672e6d3d84438d9ff35ddf811373d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=2843.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
            "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1920622701d2410d81c0e9a0600d2dac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1624.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54465fc36759463199e31c04b9b72afb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=203.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_model:{'mcc': 0.9633881068047192, 'tp': 439, 'tn': 1161, 'fp': 19, 'fn': 5, 'eval_loss': 0.08984206285478354}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuXJ6Q6u9p2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a157627c-b7e7-4725-e868-d314ea800a60"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "x = ['Count SVM', 'Roberta']\n",
        "y = [cv_desc_score,roberta_desc_mcc]\n",
        "ax.bar(x,y)\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model vs Accuracy for Job Description\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX9Q8cIn9rpU",
        "colab_type": "text"
      },
      "source": [
        "As we can see in the plot above, both models do very well in predicting fraudulent jobs from the job description. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C32LuKCfebL-",
        "colab_type": "text"
      },
      "source": [
        "#### Ensemble Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXxSfDbGec6G",
        "colab_type": "text"
      },
      "source": [
        "It seems that simple word counts and SVM do good enough performance. As we have seen earlier, `company_profile`, `description`, `benefits`, and `requirements` all have strong prediction power. As mentioned earlier, `company_profile` and `description` have the strongest power. We can do a simple ensembling of the models to average out our model and deal with potential overfitting for future usage. Word Count and default linear SVM all did very well and will be used with equal weights for all 4 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DkciiiOeaYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# Modified function to model\n",
        "def save_prediction_model(x_train, y_train, var):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_train: Training dataset\n",
        "  y_train: Predictor values for training\n",
        "  x_val: Validation/testing dataset\n",
        "  y_val: Predictor values for testing\n",
        "  var: Variable in training dataset to tokenize against\n",
        "\n",
        "  Outputs:\n",
        "  Save pickled CountVectorizer and \n",
        "  \"\"\"\n",
        "  cv = CountVectorizer(tokenizer = tokenizer, min_df = 0.01, max_df = 0.99)\n",
        "  cv1_model = cv.fit_transform(x_train[var].fillna(\"\"))\n",
        "  dump(cv, 'cv_' + var + '.joblib')  # Save Training CV\n",
        "  svc = SVC(kernel=\"linear\")\n",
        "  svc.fit(X = cv1_model, y = y_train)\n",
        "  dump(svc, 'svc_' + var + '.joblib') # Save Training SVM"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLObIgyfgDi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build training models\n",
        "for var in [\"company_profile\", \"description\", \"benefits\", \"requirements\"]:\n",
        "  save_prediction_model(x_train, y_train, var)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_-mYXogYKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction model using training data\n",
        "def predict_svm(x_test, var):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_test: Validation/testing dataset\n",
        "  var: Variable in training dataset to tokenize against\n",
        "\n",
        "  Outputs:\n",
        "  Predicted values\n",
        "  \"\"\"\n",
        "  cv = load('cv_' + var + '.joblib') \n",
        "  svc = load('svc_' + var + '.joblib') \n",
        "  cv_preds = cv.transform(x_test[var].fillna(\"\"))\n",
        "  svc_preds = svc.predict(X = cv_preds)\n",
        "  return(svc_preds)\n",
        "\n",
        "# Ensemble model by summing predictions and using cutoff of 2 for these 4 classes\n",
        "def predict_ensemble(x_test):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_test: Validation/testing dataset\n",
        "\n",
        "  Outputs:\n",
        "  Predicted value based on equally weighted predictions(n>2 = 1)\n",
        "  \"\"\"\n",
        "  preds = np.zeros((4,x_test.shape[0]))\n",
        "  preds[0,:] = predict_svm(x_test, \"company_profile\")\n",
        "  preds[1,:] = predict_svm(x_test, \"description\")\n",
        "  preds[2,:] = predict_svm(x_test, \"benefits\")\n",
        "  preds[3,:] = predict_svm(x_test, \"requirements\")\n",
        "\n",
        "  return((preds.sum(axis = 0) > 2) * 1) # Get the row based sums of predictions\n",
        "\n",
        "# Run F1 score to see overall accuracy via sensitivity/specificity\n",
        "def score_ensemble(x_test, y_test):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  x_test: Validation/testing dataset\n",
        "  y_test: Validation/testing prediction values\n",
        "\n",
        "  Outputs:\n",
        "  F1 score of ensemble model\n",
        "  \"\"\"\n",
        "  return(f1_score(y_true = y_test, y_pred = predict_ensemble(x_test)))"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gojYFOO8hWVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fbca582-0026-4f16-d018-cbab192cb0ff"
      },
      "source": [
        "score_ensemble(x_test[[\"company_profile\", \"description\", \"benefits\", \"requirements\"]], y_test)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9369797859690845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVzqv64wr5jw",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, the accuracy of this ensemble model is 93.4% which is still strong. The benefits of this approach is that in theory, there is less chance of overfitting as we have weights from different features. The ensembling is equally weighted but could be adjusted more towards a particular feature if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aaZ9cN-E7j-",
        "colab_type": "text"
      },
      "source": [
        "### Potential Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgY2VNgHE99W",
        "colab_type": "text"
      },
      "source": [
        "There are many potential things that could be done to improve the accuracy of the models. From the data cleaning aspect, there are still many things that could be done in the tokenization aspect. For instance, it looked like the multi-line text was broken done to the nearest word as there are many instances of combined words. From the modeling side, large scale hyper-parametering tuning was not performed. We might be able to squeeze out more performance by changing some fo the hyperparameters. \n",
        "Finally, there are still many models that have not been tested yet and could perform better than what is shown here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfqXQS7t1EyE",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpUzLWe1Ho3",
        "colab_type": "text"
      },
      "source": [
        "From the data we are given, it seems that we can reasonably classify if a job is frauduent using multiple features including the company profile from the job description. Although we had a large class imbalance of the data, we employed data augmentation with the text data to artifically bootstrap the data. Although the models seem to suggest that the company profile is the strongest feature, there are other useful features like like the job description, requirements, and benefits which also have good predictive power. We have seen with basic models that we can get good predictive power from text lengths. With basic NLP based models, we get very good accuracy and F1 scoring with minimal training. With more complex models like Roberta, we still get very good performance but it is comparably worse for much longer training times. For the purposes of a strong model, an ensemble model using the best paramters were chosen for the purposes of minimizing potential bias from any particular variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeAfjN0V1INw",
        "colab_type": "text"
      },
      "source": [
        "### References\n",
        "\n",
        "1. Bureau of Labor Statistics US Department of Labor. The Employment Situation - June 2020. Accessed 07/26/2020. https://www.bls.gov/news.release/pdf/empsit.pdf  \n",
        "2. USC Career Center. Avoid Fradulent Job Postings. Accessed 07/26/2020. https://careers.usc.edu/students/find-a-job/avoid-fraudulent-job-postings/  \n",
        "3. Rajapakse, Thilina. Simple Transformers - Introducing the Easiest Way To Use BERT, RoBERTa, XLNet, and XLM.Accessed 07/26/2020. https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjamXNAa1RcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}